{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOMv376ZREVW",
        "outputId": "771e7022-86c4-4f84-d2e2-9e9e2e1cb544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov  5 00:50:44 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   34C    P0             53W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!pip -q install timm transformers accelerate safetensors deepspeed bitsandbytes peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQi2_I0v_Z_j",
        "outputId": "82d51c2b-43b9-4e42-c9b7-b706e705f7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token hf_xxxxxxxxxxxxxxxxxxx"
      ],
      "metadata": {
        "id": "qUhXGDofj14x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "collapsed": true,
        "id": "4JsSXsvvg1e5",
        "outputId": "195f0fa0-ecd8-4fb4-f5d2-c9b8cde8b41b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n# 저장 폴더 생성\\n!mkdir -p /content/drive/MyDrive/vla_datasets\\n\\n\\n# 2) hub 버전은 transformers(4.57.1)와 호환되는 <1.0 유지\\n!pip -q install \"huggingface_hub==0.36.0\"\\n\\n# 3) Python API로 필요한 폴더만 다운로드\\nfrom huggingface_hub import snapshot_download\\nimport os\\n\\ntarget_dir = \"/content/drive/MyDrive/vla_datasets\"  # 원하는 저장 위치\\nos.makedirs(target_dir, exist_ok=True)\\n\\nsnapshot_download(\\n    repo_id=\"ShuaiYang03/VLA_Instruction_Tuning\",\\n    repo_type=\"dataset\",\\n    local_dir=target_dir,\\n    local_dir_use_symlinks=False,      # Drive 호환\\n)\\n\\nprint(\"다운로드 완료:\", target_dir)\\n\\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "# 저장 폴더 생성\n",
        "!mkdir -p /content/drive/MyDrive/vla_datasets\n",
        "\n",
        "\n",
        "# 2) hub 버전은 transformers(4.57.1)와 호환되는 <1.0 유지\n",
        "!pip -q install \"huggingface_hub==0.36.0\"\n",
        "\n",
        "# 3) Python API로 필요한 폴더만 다운로드\n",
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "\n",
        "target_dir = \"/content/drive/MyDrive/vla_datasets\"  # 원하는 저장 위치\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "snapshot_download(\n",
        "    repo_id=\"ShuaiYang03/VLA_Instruction_Tuning\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=target_dir,\n",
        "    local_dir_use_symlinks=False,      # Drive 호환\n",
        ")\n",
        "\n",
        "print(\"다운로드 완료:\", target_dir)\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6XbHOhcXqfT",
        "outputId": "59bd2eee-ff1a-4449-f992-439302b7d33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exists: True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/vla_project')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, pathlib\n",
        "\n",
        "DRIVE_ROOT = '/content/drive'\n",
        "MYDRIVE = f'{DRIVE_ROOT}/MyDrive'  # 한국어 UI에서도 내부 폴더명은 MyDrive\n",
        "print('exists:', os.path.exists(MYDRIVE))\n",
        "\n",
        "# 작업 폴더(예: vla_project)를 드라이브에 만들고 이동\n",
        "PROJ_DIR = f'{MYDRIVE}/vla_project'\n",
        "os.makedirs(PROJ_DIR, exist_ok=True)\n",
        "os.chdir(PROJ_DIR)\n",
        "pathlib.Path('.').resolve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mslYYQqUs50"
      },
      "outputs": [],
      "source": [
        "# 프로젝트 루트 지정\n",
        "BASE = \"/content/drive/MyDrive/vla_project\"\n",
        "\n",
        "# 필요한 디렉터리 전부 생성\n",
        "import os\n",
        "for d in [\n",
        "    BASE,\n",
        "    f\"{BASE}/data\",\n",
        "    f\"{BASE}/models\",\n",
        "    f\"{BASE}/utils\",\n",
        "    f\"{BASE}/checkpoints\",\n",
        "]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# __init__.py 더미 생성(패키지 인식용)\n",
        "for f in [\n",
        "    f\"{BASE}/__init__.py\",\n",
        "    f\"{BASE}/data/__init__.py\",\n",
        "    f\"{BASE}/models/__init__.py\",\n",
        "    f\"{BASE}/utils/__init__.py\",\n",
        "]:\n",
        "    if not os.path.exists(f):\n",
        "        with open(f, \"w\", encoding=\"utf-8\") as fp:\n",
        "            fp.write(\"# package\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8faK7C1RFQz",
        "outputId": "cb80abd1-715d-4b18-d340-2ffd95eb6568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/config.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/vla_project/config.py\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    # -----------------------------\n",
        "    # Data (VLA RLDS / TFDS)\n",
        "    # -----------------------------\n",
        "    # TFDS builder directory (Bridge / Fractal)\n",
        "    builder_dir: str = \"/content/drive/MyDrive/vla_datasets/bridge_dataset/1.0.0\"\n",
        "    # reasoning json (Bridge instruction)\n",
        "    reasoning_json: str = \"/content/drive/MyDrive/vla_datasets/annotation/bridge_instruction.json\"\n",
        "    # train / val split ratios\n",
        "    train_split: str = \"train[:80%]\"\n",
        "    val_split: str   = \"train[80%:]\"\n",
        "    # image resize\n",
        "    img_size: int = 224\n",
        "\n",
        "    # dataloader options\n",
        "    batch_size: int = 32\n",
        "    val_batch_size: int = 32\n",
        "    num_workers: int = 0\n",
        "    pin_memory: bool = True\n",
        "\n",
        "    viz_episode_id: str | None = None              # 시각화할 episode_id (None이면 자동탐색)\n",
        "    viz_max_frames_per_episode: int = 128          # 에피소드 최대 프레임\n",
        "\n",
        "    # -----------------------------\n",
        "    # Logging / Checkpoints\n",
        "    # -----------------------------\n",
        "    ckpt_dir: str = \"checkpoints\"\n",
        "    log_interval: int = 50\n",
        "    eval_interval: int = 500\n",
        "    save_interval: int = 1000\n",
        "    viz_interval: int = 5\n",
        "\n",
        "    # -----------------------------\n",
        "    # Model / Backbones\n",
        "    # -----------------------------\n",
        "    img_channels: int = 3\n",
        "    img_size: int = 518\n",
        "    vision_backbone: str = \"vit_base_patch14_dinov2\"  # timm backbone\n",
        "    text_model_name: str = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "    #rl\n",
        "    rl_state_dim: int = 7\n",
        "    rl_action_dim: int = 7\n",
        "    rl_hidden_dim: int = 1024\n",
        "\n",
        "    # embedding / dims\n",
        "    vision_embed_dim: int = 768\n",
        "    text_embed_dim: int = 4096\n",
        "    state_dim: int = 7\n",
        "    action_dim: int = 7\n",
        "    hidden_dim: int = 1024\n",
        "\n",
        "    # tokenizer settings\n",
        "    text_max_len: int = 256\n",
        "    pad_token_str: str = \"<|pad|>\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # LoRA (for LLM fine-tuning)\n",
        "    # -----------------------------\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 32\n",
        "    lora_dropout: float = 0.1\n",
        "\n",
        "    # -----------------------------\n",
        "    # Training\n",
        "    # -----------------------------\n",
        "    epochs: int = 10\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    amp: bool = True\n",
        "    grad_clip: float = 1.0\n",
        "    seed: int = 42\n",
        "\n",
        "    # -----------------------------\n",
        "    # DeepSpeed / Distributed\n",
        "    # -----------------------------\n",
        "    use_deepspeed: bool = False\n",
        "    deepspeed_config: str = \"ds_config.json\"\n",
        "    grad_accumulation_steps: int = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaZaomik1K9H",
        "outputId": "899f0639-6328-4637-c4ec-8c877739032c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/util.py\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# file: utils.py\n",
        "# -----------------------------\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/util.py\n",
        "\n",
        "\n",
        "import os, random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def save_checkpoint(path, state_dict):\n",
        "  os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "  torch.save(state_dict, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lxmN77WWv9K",
        "outputId": "e8f4d852-7832-4299-f36c-011333291cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/utils/vis.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/vla_project/utils/vis.py\n",
        "\n",
        "# utils/vis.py\n",
        "import re\n",
        "import torch\n",
        "@torch.no_grad()\n",
        "def viz_episode(model_like, loader, device, target_episode_id, out_mp4, max_frames=256):\n",
        "    \"\"\"\n",
        "    loader에서 target_episode_id인 샘플만 모아 step 오름차순으로 정렬 후,\n",
        "    추론하여 mp4로 저장.\n",
        "    \"\"\"\n",
        "    model_like.eval()\n",
        "    from utils.vis import make_preview_tile, VideoLogger\n",
        "    vlog = VideoLogger(out_mp4=out_mp4, fps=4)\n",
        "\n",
        "    def _to_py(x):\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            x = x.detach().cpu()\n",
        "            return x.item() if x.numel() == 1 else x.tolist()\n",
        "        return x\n",
        "\n",
        "    def _get_step(i, aux):\n",
        "        # aux['step'|'t'|'frame_idx'] 우선, 없으면 file_path에서 숫자 파싱\n",
        "        for k in (\"step\",\"t\",\"frame_idx\",\"index\"):\n",
        "            if k in aux and aux[k] is not None:\n",
        "                v = aux[k][i]\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    v = v.detach().cpu().item() if v.numel()==1 else int(v.detach().cpu().tolist())\n",
        "                try: return int(v)\n",
        "                except: pass\n",
        "        fp = aux.get(\"file_path\", None)\n",
        "        if fp is not None:\n",
        "            s = fp[i] if isinstance(fp, (list,tuple)) else fp\n",
        "            s = str(s)\n",
        "            nums = re.findall(r\"\\d+\", s)\n",
        "            if nums:\n",
        "                try: return int(nums[-1])\n",
        "                except: return None\n",
        "        return None\n",
        "\n",
        "    # 1) target episode만 수집\n",
        "    bucket = []  # [(step, (imgs_j, txt_j, states_j, acts_j, aux_slice_j))]\n",
        "    for batch in loader:\n",
        "        ep = batch[\"aux\"][\"episode_id\"]\n",
        "        imgs = batch[\"image\"]\n",
        "        texts = batch[\"text\"]\n",
        "        states = batch[\"state\"]\n",
        "        acts = batch[\"action\"]\n",
        "        aux = batch[\"aux\"]\n",
        "\n",
        "        B = imgs.size(0) if hasattr(imgs, \"size\") else 1\n",
        "        # 리스트/텐서 → 파이썬/리스트\n",
        "        if isinstance(ep, torch.Tensor): ep = ep.detach().cpu().tolist()\n",
        "        if not isinstance(ep, (list,tuple)): ep = [ep]*B\n",
        "        txt_list = texts if isinstance(texts, (list,tuple)) else [str(texts)]*B\n",
        "\n",
        "        for i in range(B):\n",
        "            if ep[i] != target_episode_id:\n",
        "                continue\n",
        "            step_i = _get_step(i, aux)\n",
        "            # 개별 샘플 슬라이스 준비 (CPU 상에서 보관)\n",
        "            imgs_i = imgs[i].cpu()\n",
        "            states_i = states[i].cpu() if isinstance(states, torch.Tensor) else states\n",
        "            acts_i = torch.as_tensor(acts[i]).cpu()\n",
        "            # 텍스트는 str로\n",
        "            txt_i = str(txt_list[i]) if i < len(txt_list) else str(txt_list[0])\n",
        "            # 필요한 aux 일부만\n",
        "            aux_i = {k: (v[i] if isinstance(v, (list,tuple)) else v) for k,v in aux.items() if k in (\"file_path\",\"episode_id\")}\n",
        "            bucket.append((step_i, (imgs_i, txt_i, states_i, acts_i, aux_i)))\n",
        "            if len(bucket) >= max_frames: break\n",
        "        if len(bucket) >= max_frames: break\n",
        "\n",
        "    if not bucket:\n",
        "        print(f\"[viz-episode] episode_id={target_episode_id} 를 찾지 못했습니다.\")\n",
        "        vlog.close()\n",
        "        return\n",
        "\n",
        "    # 2) step 기준 정렬\n",
        "    # step 정보 없는 항목(None)은 뒤로 보냄\n",
        "    bucket.sort(key=lambda x: (999999999 if x[0] is None else x[0]))\n",
        "\n",
        "    # 3) 순회하며 추론/타일화\n",
        "    for step_i, pack in bucket:\n",
        "        imgs_i, txt_i, states_i, acts_i, aux_i = pack\n",
        "        imgs_i = imgs_i.unsqueeze(0).to(device, non_blocking=True)   # [1,3,H,W]\n",
        "        states_i = states_i.unsqueeze(0).to(device, non_blocking=True) if isinstance(states_i, torch.Tensor) else states_i\n",
        "        acts_i = acts_i.unsqueeze(0).to(device, non_blocking=True)\n",
        "\n",
        "        # 모델 호출 시 your forward 시그니처에 맞추기\n",
        "        try:\n",
        "            pred_i = model_like(imgs_i, [txt_i], states_i)\n",
        "        except TypeError:\n",
        "            pred_i = model_like(imgs_i, [txt_i])  # states 미사용 모델일 때\n",
        "\n",
        "        tile = make_preview_tile(\n",
        "            images=imgs_i, texts=[txt_i], states=states_i,\n",
        "            gt_actions=acts_i, pred_actions=pred_i,\n",
        "            max_n=1, downscale=1.0, which=0\n",
        "        )\n",
        "        vlog.write_pil(tile, async_save=False)\n",
        "    vlog.close()\n",
        "    print(f\"[viz-episode] episode_id={target_episode_id} → {out_mp4} 저장 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ54LDLF1LCZ",
        "outputId": "854821ce-b144-4d61-8e94-cf3968ab83c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/data/data.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/vla_project/data/data.py\n",
        "# /content/drive/MyDrive/vla_project/data/data.py\n",
        "import os, io, json\n",
        "from typing import Dict, Any, List, Iterator, Optional\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 유틸 함수\n",
        "# -----------------------------\n",
        "def _tf_to_numpy(x):\n",
        "    \"\"\"tf.Tensor or EagerTensor -> np.ndarray or Python scalar\"\"\"\n",
        "    if hasattr(x, \"numpy\"):\n",
        "        return x.numpy()\n",
        "    return x  # 이미 numpy나 파이썬 타입인 경우\n",
        "\n",
        "def _decode_str(x):\n",
        "    \"\"\"bytes/tf.string -> str\"\"\"\n",
        "    if hasattr(x, \"numpy\"):\n",
        "        v = x.numpy()\n",
        "        if isinstance(v, (bytes, bytearray)):\n",
        "            return v.decode(\"utf-8\", errors=\"ignore\")\n",
        "        return str(v)\n",
        "    if isinstance(x, (bytes, bytearray)):\n",
        "        return x.decode(\"utf-8\", errors=\"ignore\")\n",
        "    return str(x)\n",
        "\n",
        "def _to_image_tensor(img: np.ndarray, size: int = 224) -> torch.Tensor:\n",
        "    \"\"\"HxWx3 uint8 -> (3, H, W) float32[0~1]\"\"\"\n",
        "    if img.ndim != 3 or img.shape[2] != 3:\n",
        "        raise ValueError(f\"expected HxWx3, got {img.shape}\")\n",
        "    pil = Image.fromarray(img).resize((size, size))\n",
        "    arr = np.asarray(pil, dtype=np.float32) / 255.0\n",
        "    arr = np.transpose(arr, (2, 0, 1))  # to CHW\n",
        "    return torch.from_numpy(arr)\n",
        "\n",
        "def _image_from_step(st: Dict[str, Any]) -> np.ndarray:\n",
        "    \"\"\"우선순위: observation.image_0 (필요시 다른 카메라도 확장 가능)\"\"\"\n",
        "    obs = st.get(\"observation\", {})\n",
        "    if \"image_0\" in obs:\n",
        "        return _tf_to_numpy(obs[\"image_0\"])\n",
        "    # fallback (데이터셋 변형용)\n",
        "    if \"image\" in st:\n",
        "        return _tf_to_numpy(st[\"image\"])\n",
        "    raise KeyError(\"No image key found in step (expected observation.image_0)\")\n",
        "\n",
        "def _maybe_to_torch_1d(x) -> Optional[torch.Tensor]:\n",
        "    if x is None:\n",
        "        return None\n",
        "    x = _tf_to_numpy(x)\n",
        "    x = np.asarray(x)\n",
        "    if x.ndim == 0:  # scalar -> (1,)\n",
        "        x = x[None]\n",
        "    return torch.from_numpy(x.astype(np.float32, copy=False))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Reasoning Lookup (선택)\n",
        "# -----------------------------\n",
        "class ReasoningLookup:\n",
        "    \"\"\"\n",
        "    reasoning_json 파일 구조 예시:\n",
        "    {\n",
        "      \"/abs/path/to/out.npy\": {\n",
        "        \"43\": {\n",
        "          \"features\": {\"move_primitive\": [\"stop\", \"pick\", ...]},\n",
        "          \"alt_instruction\": {...}\n",
        "        },\n",
        "        ...\n",
        "      },\n",
        "      ...\n",
        "    }\n",
        "    \"\"\"\n",
        "    def __init__(self, json_path: str, primitive_to_id: bool = False):\n",
        "        self.tbl = {}\n",
        "        self.primitive2id = None\n",
        "\n",
        "        if not json_path or not os.path.isfile(json_path):\n",
        "            print(f\"[WARN] reasoning JSON not found: {json_path}\")\n",
        "            return\n",
        "\n",
        "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            raw = json.load(f)\n",
        "\n",
        "        # (옵션) 프리미티브 사전 구성\n",
        "        if primitive_to_id:\n",
        "            uniq = set()\n",
        "            for _, epdict in raw.items():\n",
        "                for _, content in epdict.items():\n",
        "                    for mp in content.get(\"features\", {}).get(\"move_primitive\", []):\n",
        "                        uniq.add(mp)\n",
        "            self.primitive2id = {p: i for i, p in enumerate(sorted(uniq))}\n",
        "            print(f\"[INFO] primitive2id built: {len(self.primitive2id)} labels\")\n",
        "\n",
        "        cnt = 0\n",
        "        for file_name, epdict in raw.items():\n",
        "            for ep_id, content in epdict.items():\n",
        "                moves = content.get(\"features\", {}).get(\"move_primitive\", [])\n",
        "                for i, mp in enumerate(moves):\n",
        "                    key = f\"{file_name}_{ep_id}_{i}\"\n",
        "                    if self.primitive2id is not None:\n",
        "                        mp_val = self.primitive2id.get(mp, -1)\n",
        "                    else:\n",
        "                        mp_val = mp\n",
        "                    self.tbl[key] = {\n",
        "                        \"move_primitive\": mp_val,\n",
        "                        \"alt_instruction\": content.get(\"alt_instruction\", None),\n",
        "                    }\n",
        "                    cnt += 1\n",
        "        print(f\"[INFO] reasoning entries: {cnt}\")\n",
        "\n",
        "    def get(self, file_path: str, ep_id: int, idx: int):\n",
        "        key = f\"{file_path}_{ep_id}_{idx}\"\n",
        "        return self.tbl.get(key, {})\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class VLADataset(IterableDataset):\n",
        "    \"\"\"\n",
        "    TFDS 에피소드 구조(사용자 제공 spec 기준):\n",
        "\n",
        "    Top-level keys: ['episode_metadata', 'steps']\n",
        "    episode_metadata keys: ['episode_id', 'file_path', 'has_image_0', 'has_image_1', 'has_image_2', 'has_image_3', 'has_language']\n",
        "\n",
        "    steps.element_spec:\n",
        "      - action: (7,) float32\n",
        "      - discount: () float32\n",
        "      - is_first/is_last/is_terminal: () bool\n",
        "      - language_embedding: (512,) float32\n",
        "      - language_instruction: () string\n",
        "      - observation:\n",
        "          image_0..image_3: (256,256,3) uint8\n",
        "          state: (7,) float32\n",
        "      - reward: () float32\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        builder_dir: str,\n",
        "        split: str = \"train[:80%]\",\n",
        "        reasoning_json: Optional[str] = None,   # 선택\n",
        "        map_primitive_to_id: bool = False,      # 선택\n",
        "        img_size: int = 224,\n",
        "        verbose: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.builder_dir = builder_dir\n",
        "        self.split = split\n",
        "        self.img_size = img_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # GPU mem growth (TF)\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        for g in gpus:\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(g, True)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        self.builder = tfds.builder_from_directory(builder_dir=self.builder_dir)\n",
        "\n",
        "        # reasoning lookup (선택)\n",
        "        self.reasoning = None\n",
        "        if reasoning_json:\n",
        "            self.reasoning = ReasoningLookup(reasoning_json, primitive_to_id=map_primitive_to_id)\n",
        "\n",
        "    def __iter__(self) -> Iterator[Dict[str, Any]]:\n",
        "        ds = self.builder.as_dataset(split=self.split)\n",
        "\n",
        "        for ep in ds:\n",
        "            meta = ep[\"episode_metadata\"]\n",
        "            file_path = _decode_str(meta.get(\"file_path\", \"\"))\n",
        "            ep_id = int(_tf_to_numpy(meta.get(\"episode_id\", 0)))\n",
        "\n",
        "            steps = ep[\"steps\"]\n",
        "            # TF 2 eager에서는 파이썬 for-iter 지원. 환경에 따라 as_numpy_iterator() 사용 가능.\n",
        "            for i, st in enumerate(steps):\n",
        "                # 이미지\n",
        "                img_np = _image_from_step(st)\n",
        "                img = _to_image_tensor(img_np, self.img_size)\n",
        "\n",
        "                # 언어 지시문\n",
        "                instr = _decode_str(st.get(\"language_instruction\", b\"\"))\n",
        "\n",
        "                # 언어 임베딩 (512,)\n",
        "                lang_emb = st.get(\"language_embedding\", None)\n",
        "                lang_emb_t = _maybe_to_torch_1d(lang_emb)\n",
        "\n",
        "                # 상태 (7,)\n",
        "                state = st.get(\"observation\", {}).get(\"state\", None)\n",
        "                state_t = _maybe_to_torch_1d(state)\n",
        "\n",
        "                # 액션 (7,)\n",
        "                action = st.get(\"action\", None)\n",
        "                action_t = _maybe_to_torch_1d(action)\n",
        "\n",
        "                # 보상/디스카운트/플래그\n",
        "                reward = st.get(\"reward\", None)\n",
        "                discount = st.get(\"discount\", None)\n",
        "                is_first = st.get(\"is_first\", None)\n",
        "                is_last = st.get(\"is_last\", None)\n",
        "                is_terminal = st.get(\"is_terminal\", None)\n",
        "\n",
        "                reward_v = float(_tf_to_numpy(reward)) if reward is not None else 0.0\n",
        "                discount_v = float(_tf_to_numpy(discount)) if discount is not None else 1.0\n",
        "                is_first_v = bool(_tf_to_numpy(is_first)) if is_first is not None else False\n",
        "                is_last_v = bool(_tf_to_numpy(is_last)) if is_last is not None else False\n",
        "                is_terminal_v = bool(_tf_to_numpy(is_terminal)) if is_terminal is not None else False\n",
        "\n",
        "                # reasoning 매칭 (move_primitive 등)\n",
        "                move_primitive = None\n",
        "                if self.reasoning:\n",
        "                    r = self.reasoning.get(file_path, ep_id, i)\n",
        "                    move_primitive = r.get(\"move_primitive\", None)\n",
        "                    # instruction이 비어있고 대체 문구가 있으면 Caption 사용\n",
        "                    if not instr and isinstance(r.get(\"alt_instruction\"), dict):\n",
        "                        instr = r[\"alt_instruction\"].get(\"Caption\", \"\") or \"\"\n",
        "\n",
        "                yield dict(\n",
        "                    image=img,                               # (3,H,W) float32\n",
        "                    instruction=instr or \"\",                 # str\n",
        "                    language_embedding=lang_emb_t,           # (512,) float32 or None\n",
        "                    action=action_t,                         # (7,) float32 or None\n",
        "                    state=state_t,                           # (7,) float32 or None\n",
        "                    reward=reward_v,                         # float\n",
        "                    discount=discount_v,                     # float\n",
        "                    is_first=is_first_v,                     # bool\n",
        "                    is_last=is_last_v,                       # bool\n",
        "                    is_terminal=is_terminal_v,               # bool\n",
        "                    move_primitive=move_primitive,           # str or int or None\n",
        "                    file_path=file_path,                     # str\n",
        "                    episode_id=ep_id,                        # int\n",
        "                    step_idx=i,                              # int\n",
        "                )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Collate\n",
        "# -----------------------------\n",
        "def _stack_or_none(items: List[Optional[torch.Tensor]]) -> Optional[torch.Tensor]:\n",
        "    \"\"\"리스트에서 None 제외하고 stack. 전부 None이면 None.\"\"\"\n",
        "    buf = [x for x in items if x is not None]\n",
        "    if not buf:\n",
        "        return None\n",
        "    return torch.stack(buf, dim=0)\n",
        "\n",
        "def collate_vla(batch: List[Dict[str, Any]]):\n",
        "    # 필수\n",
        "    imgs = torch.stack([b[\"image\"] for b in batch])  # (B,3,H,W)\n",
        "    texts = [b[\"instruction\"] for b in batch]\n",
        "    moves = [b[\"move_primitive\"] for b in batch]\n",
        "\n",
        "    # 선택 텐서들\n",
        "    lang_embs = _stack_or_none([b.get(\"language_embedding\") for b in batch])  # (B,512) or None\n",
        "    actions   = _stack_or_none([b.get(\"action\") for b in batch])              # (B,7) or None\n",
        "    states    = _stack_or_none([b.get(\"state\") for b in batch])               # (B,7) or None\n",
        "\n",
        "    rewards   = torch.tensor([b.get(\"reward\", 0.0) for b in batch], dtype=torch.float32)\n",
        "    discounts = torch.tensor([b.get(\"discount\", 1.0) for b in batch], dtype=torch.float32)\n",
        "    is_first  = torch.tensor([1.0 if b.get(\"is_first\", False) else 0.0 for b in batch], dtype=torch.float32)\n",
        "    is_last   = torch.tensor([1.0 if b.get(\"is_last\", False) else 0.0 for b in batch], dtype=torch.float32)\n",
        "    is_term   = torch.tensor([1.0 if b.get(\"is_terminal\", False) else 0.0 for b in batch], dtype=torch.float32)\n",
        "\n",
        "    aux = {\n",
        "        \"file_path\": [b[\"file_path\"] for b in batch],\n",
        "        \"episode_id\": [b[\"episode_id\"] for b in batch],\n",
        "        \"step_idx\": [b[\"step_idx\"] for b in batch],\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"image\": imgs,\n",
        "        \"text\": texts,\n",
        "        \"move_primitive\": moves,          # str list or int list (ReasoningLookup 설정에 따라)\n",
        "        \"language_embedding\": lang_embs,  # or None\n",
        "        \"action\": actions,                # or None\n",
        "        \"state\": states,                  # or None\n",
        "        \"reward\": rewards,\n",
        "        \"discount\": discounts,\n",
        "        \"is_first\": is_first,\n",
        "        \"is_last\": is_last,\n",
        "        \"is_terminal\": is_term,\n",
        "        \"aux\": aux,\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# make_dataloaders\n",
        "# -----------------------------\n",
        "def make_dataloaders(cfg):\n",
        "    \"\"\"\n",
        "    cfg 필수/옵션:\n",
        "      - cfg.builder_dir (str)\n",
        "      - cfg.img_size (int)\n",
        "      - cfg.batch_size (int)\n",
        "      - cfg.train_split (str, optional, default \"train[:80%]\")\n",
        "      - cfg.val_split   (str, optional, default \"train[80%:]\")\n",
        "      - cfg.reasoning_json (str or None)\n",
        "      - cfg.map_primitive_to_id (bool, default False)\n",
        "      - cfg.num_workers (int, default 0)\n",
        "      - cfg.shuffle_buffer (int, optional; IterableDataset에서는 보통 외부 셔플러 필요)\n",
        "    \"\"\"\n",
        "    train_ds = VLADataset(\n",
        "        builder_dir=cfg.builder_dir,\n",
        "        split=getattr(cfg, \"train_split\", \"train[:80%]\"),\n",
        "        reasoning_json=getattr(cfg, \"reasoning_json\", None),\n",
        "        map_primitive_to_id=getattr(cfg, \"map_primitive_to_id\", False),\n",
        "        img_size=cfg.img_size,\n",
        "    )\n",
        "    val_ds = VLADataset(\n",
        "        builder_dir=cfg.builder_dir,\n",
        "        split=getattr(cfg, \"val_split\", \"train[80%:]\"),\n",
        "        reasoning_json=getattr(cfg, \"reasoning_json\", None),\n",
        "        map_primitive_to_id=getattr(cfg, \"map_primitive_to_id\", False),\n",
        "        img_size=cfg.img_size,\n",
        "    )\n",
        "\n",
        "    nw = int(getattr(cfg, \"num_workers\", 0))\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=cfg.batch_size, num_workers=nw, collate_fn=collate_vla\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_ds, batch_size=cfg.batch_size, num_workers=nw, collate_fn=collate_vla\n",
        "    )\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utr61vxNBOMx",
        "outputId": "aa174593-e654-4c4e-fe72-3b64ef3d14e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/models/vision.py\n"
          ]
        }
      ],
      "source": [
        "# file :  models/vision.py\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/models/vision.py\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class DinoV2Encoder(nn.Module):\n",
        "    def __init__(self, model_name: str, embed_dim: int):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
        "        out_dim = getattr(self.backbone, \"num_features\", embed_dim)\n",
        "        self.proj = nn.Identity() if out_dim == embed_dim else nn.Linear(out_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)   # [B, C]\n",
        "        return self.proj(feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZqCfJgIPUL9"
      },
      "outputs": [],
      "source": [
        "# 디렉토리 생성\n",
        "%%bash\n",
        "mkdir -p /content/drive/MyDrive/vla_project/models/llm_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp4qF9G1QkbS",
        "outputId": "92aa503d-8098-4e91-b809-232b0d679d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/models/llm_func/__init__.py\n"
          ]
        }
      ],
      "source": [
        "# models/llm_func/__init__.py\n",
        "%%writefile /content/drive/MyDrive/vla_project/models/llm_func/__init__.py\n",
        "# llm_func package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUMO71KaMLwv",
        "outputId": "25a32374-b06c-4a66-ffda-beff9bce1d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/models/llm_func/lora_ft.py\n"
          ]
        }
      ],
      "source": [
        "# models/llm_func/lora_ft.py — LLaMA 백본만 LoRA-FT (클래스 버전)\n",
        "%%writefile /content/drive/MyDrive/vla_project/models/llm_func/lora_ft.py\n",
        "from typing import Iterable, Tuple, Optional, List\n",
        "import torch.nn as nn\n",
        "\n",
        "try:\n",
        "    from peft import LoraConfig, get_peft_model, PeftModel\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"peft가 필요합니다. `pip install peft`\") from e\n",
        "\n",
        "\n",
        "DEFAULT_LLAMA_TARGET_MODULES: List[str] = [\n",
        "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "    \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "]\n",
        "\n",
        "\n",
        "class LoraFTManager:\n",
        "    \"\"\"\n",
        "    - 전체 모델을 동결하고, model.text.backbone(HF LLaMA) 에만 LoRA 부착\n",
        "    - 필요한 경우 GC(gradient checkpointing) 활성화\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        *,\n",
        "        target_modules: Optional[Iterable[str]] = None,\n",
        "        bias: str = \"none\",\n",
        "        task_type: str = \"CAUSAL_LM\"\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.target_modules = list(target_modules) if target_modules is not None else list(DEFAULT_LLAMA_TARGET_MODULES)\n",
        "        self.bias = bias\n",
        "        self.task_type = task_type\n",
        "\n",
        "    # --------- public API ---------\n",
        "    def freeze_all(self) -> None:\n",
        "        self._set_requires_grad(self.model, False)\n",
        "\n",
        "    def attach(\n",
        "        self,\n",
        "        *,\n",
        "        r: int = 8,\n",
        "        alpha: int = 32,\n",
        "        dropout: float = 0.1,\n",
        "        gradient_checkpointing: bool = True,\n",
        "        print_report: bool = True,\n",
        "    ) -> nn.Module:\n",
        "        \"\"\"LoRA를 LLaMA 백본에만 부착하고 나머지는 동결.\"\"\"\n",
        "        self.freeze_all()\n",
        "        llama = self._get_llama_backbone()\n",
        "\n",
        "        cfg = LoraConfig(\n",
        "            r=r,\n",
        "            lora_alpha=alpha,\n",
        "            lora_dropout=dropout,\n",
        "            target_modules=self.target_modules,\n",
        "            bias=self.bias,\n",
        "            task_type=self.task_type,\n",
        "        )\n",
        "        lora_llama = get_peft_model(llama, cfg)\n",
        "\n",
        "        if gradient_checkpointing and hasattr(lora_llama, \"gradient_checkpointing_enable\"):\n",
        "            try:\n",
        "                lora_llama.gradient_checkpointing_enable()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # VLA에 장착\n",
        "        self._set_text_backbone(lora_llama)\n",
        "\n",
        "        if print_report:\n",
        "            try:\n",
        "                lora_llama.print_trainable_parameters()\n",
        "            except Exception:\n",
        "                tr, fr = self.count_params()\n",
        "                print(f\"[LoRA] trainable={tr:,} frozen={fr:,}\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def is_attached(self) -> bool:\n",
        "        try:\n",
        "            return isinstance(self._get_llama_backbone(), PeftModel)\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    def save_adapters(self, save_dir: str) -> None:\n",
        "        \"\"\"LoRA 어댑터만 저장.\"\"\"\n",
        "        llm = self._get_llama_backbone()\n",
        "        if not isinstance(llm, PeftModel):\n",
        "            raise RuntimeError(\"LoRA가 부착되어 있지 않습니다.\")\n",
        "        llm.save_pretrained(save_dir)\n",
        "        print(f\"[LoRA] adapters saved to: {save_dir}\")\n",
        "\n",
        "    def count_params(self) -> Tuple[int, int]:\n",
        "        trainable, frozen = 0, 0\n",
        "        for p in self.model.parameters():\n",
        "            (trainable if p.requires_grad else frozen).__iadd__(p.numel())\n",
        "        return trainable, frozen\n",
        "\n",
        "    # --------- internals ---------\n",
        "    @staticmethod\n",
        "    def _set_requires_grad(module: nn.Module, flag: bool) -> None:\n",
        "        for p in module.parameters():\n",
        "            p.requires_grad = flag\n",
        "\n",
        "    def _get_llama_backbone(self) -> nn.Module:\n",
        "        \"\"\"\n",
        "        VLA 구현에서 텍스트 백본을 model.text.backbone 으로 가정.\n",
        "        다르면 이 메서드를 수정하세요.\n",
        "        \"\"\"\n",
        "        text = getattr(self.model, \"text\", None)\n",
        "        if text is None:\n",
        "            raise RuntimeError(\"model.text 를 찾을 수 없습니다. VLA 구현을 확인하세요.\")\n",
        "        backbone = getattr(text, \"backbone\", None)\n",
        "        if backbone is None:\n",
        "            raise RuntimeError(\"model.text.backbone 을 찾을 수 없습니다. VLA 구현을 확인하세요.\")\n",
        "        return backbone\n",
        "\n",
        "    def _set_text_backbone(self, new_backbone: nn.Module) -> None:\n",
        "        text = getattr(self.model, \"text\", None)\n",
        "        if text is None:\n",
        "            raise RuntimeError(\"model.text 를 찾을 수 없습니다.\")\n",
        "        setattr(text, \"backbone\", new_backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJNEElGLCXMH",
        "outputId": "67fc8125-102c-47d1-a954-0aec30184156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/models/text.py\n"
          ]
        }
      ],
      "source": [
        "# file: models/text.py\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/models/text.py\n",
        "\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "class LlamaTextEncoder(nn.Module):\n",
        "    def __init__(self, model_name: str, embed_dim: int,\n",
        "                 fp16: bool = True, pad_token_str: str = \"<|pad|>\",\n",
        "                 max_len: int = 256):\n",
        "        super().__init__()\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.add_special_tokens({\"pad_token\": pad_token_str})\n",
        "        self.max_len = int(max_len)\n",
        "        self.tokenizer.model_max_length = self.max_len\n",
        "\n",
        "        dtype = torch.float16 if fp16 else None\n",
        "        self.backbone = AutoModel.from_pretrained(model_name, dtype=dtype)\n",
        "\n",
        "        if len(self.tokenizer) != self.backbone.get_input_embeddings().num_embeddings:\n",
        "            self.backbone.resize_token_embeddings(len(self.tokenizer))\n",
        "\n",
        "        self.hidden_size = self.backbone.config.hidden_size\n",
        "        self.embed_dim   = embed_dim\n",
        "        self.proj = nn.Linear(self.hidden_size, self.embed_dim, bias=False) \\\n",
        "                    if self.hidden_size != self.embed_dim else nn.Identity()\n",
        "\n",
        "    def forward(self, texts):\n",
        "        # texts: list[str] 보장 (VLA에서 강제)\n",
        "        if isinstance(texts, (list, tuple)):\n",
        "            txt_list = [t if isinstance(t, str) else str(t) for t in texts]\n",
        "        else:\n",
        "            txt_list = [str(texts)]\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            txt_list, padding=True, truncation=True,\n",
        "            max_length=self.max_len, return_tensors=\"pt\"\n",
        "        )\n",
        "        device = next(self.backbone.parameters()).device\n",
        "        enc = {k: v.to(device, non_blocking=True) for k, v in enc.items()}\n",
        "\n",
        "        if not hasattr(self, \"_dbg_tok\"):\n",
        "            print(f\"[DBG/TEXT] input_ids={tuple(enc['input_ids'].shape)}\", flush=True)\n",
        "            self._dbg_tok = True\n",
        "\n",
        "        out = self.backbone(**enc)                 # [B, T, H]\n",
        "        t_feat = out.last_hidden_state.mean(dim=1) # [B, H]\n",
        "        t_feat = self.proj(t_feat)                 # [B, embed_dim]\n",
        "        return t_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpGyrff3CXOa",
        "outputId": "0deea7bb-546c-42d6-84ee-e7118107d191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/models/policy.py\n"
          ]
        }
      ],
      "source": [
        "#file models/policy.py\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/models/policy.py\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class PolicyHead(nn.Module):\n",
        "    def __init__(self, vision_dim: int, text_dim: int, state_dim: int, hidden_dim: int, action_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(vision_dim + text_dim + state_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, action_dim),\n",
        "        )\n",
        "    def forward(self, v, t , s):\n",
        "\n",
        "        x = torch.cat([v, t , s], dim=-1)\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2TfY3zKGYPw",
        "outputId": "e8967985-d434-4236-fc67-a1d372fdee34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/models/vla.py\n"
          ]
        }
      ],
      "source": [
        "#file models/vla.py\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/models/vla.py\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from models.vision import DinoV2Encoder\n",
        "from models.text import LlamaTextEncoder\n",
        "from models.policy import PolicyHead\n",
        "\n",
        "class VLA(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vision_backbone: str, vision_embed_dim: int,\n",
        "                 text_model_name: str, text_embed_dim: int,\n",
        "                 state_dim: int,\n",
        "                 hidden_dim: int, action_dim: int,\n",
        "                 fp16_text: bool = True, pad_token_str: str = \"<|pad|>\",\n",
        "                 text_max_len: int = 256):\n",
        "        super().__init__()\n",
        "        self.vision = DinoV2Encoder(model_name=vision_backbone, embed_dim=vision_embed_dim)\n",
        "        self.text   = LlamaTextEncoder(model_name=text_model_name, embed_dim=text_embed_dim,\n",
        "                                       fp16=fp16_text, pad_token_str=pad_token_str,\n",
        "                                       max_len=text_max_len)\n",
        "        self.policy = PolicyHead(\n",
        "            vision_dim=vision_embed_dim,\n",
        "            text_dim=text_embed_dim,\n",
        "            state_dim = state_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            action_dim=action_dim,\n",
        "        )\n",
        "\n",
        "    def forward(self, images, texts , states):\n",
        "\n",
        "        B = images.size(0)\n",
        "        v = self.vision(images)  # [B, V]\n",
        "        texts = self.text(texts)  # [B, Tdim]\n",
        "        return self.policy(v, texts , states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R80N7bOIHU6v",
        "outputId": "4f7844ee-c362-41a2-af6e-a44342bdbd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/losses.py\n"
          ]
        }
      ],
      "source": [
        "# loss.py\n",
        "\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/losses.py\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "def action_loss(logits: torch.Tensor, target: torch.Tensor):\n",
        "    # logits: [B, C], target: [B, C] (float)\n",
        "    if target.dtype != logits.dtype:\n",
        "        target = target.to(logits.dtype)\n",
        "    assert target.shape == logits.shape, f\"shape mismatch: {logits.shape} vs {target.shape}\"\n",
        "    return F.mse_loss(logits, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUpPXqyEE-lZ"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir -p /content/drive/MyDrive/vla_project/{trainers,utils,data}\n",
        "\n",
        "#touch /content/drive/MyDrive/vla_project/trainers/__init__.py\n",
        "#touch /content/drive/MyDrive/vla_project/utils/__init__.py\n",
        "#touch /content/drive/MyDrive/vla_project/dataio/__init__.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTCiGxJHFA57",
        "outputId": "b0f48790-6cef-46f3-d435-c9620fe2476f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/utils/progress.py\n"
          ]
        }
      ],
      "source": [
        "# utils/progress.py — 진행상황 계산 유틸들\n",
        "%%writefile /content/drive/MyDrive/vla_project/utils/progress.py\n",
        "import torch, math, time\n",
        "\n",
        "class SmoothedValue:\n",
        "    def __init__(self, momentum: float = 0.98):\n",
        "        self.m = None\n",
        "        self.beta = momentum\n",
        "    def update(self, x: float):\n",
        "        if x is None: return\n",
        "        self.m = x if self.m is None else (self.beta * self.m + (1 - self.beta) * x)\n",
        "    @property\n",
        "    def value(self):\n",
        "        return float(\"nan\") if self.m is None else float(self.m)\n",
        "\n",
        "def get_lr(optimizer=None, ds_engine=None):\n",
        "    if ds_engine is not None:\n",
        "        try:\n",
        "            pg = ds_engine.optimizer.param_groups\n",
        "            if pg and \"lr\" in pg[0]:\n",
        "                return pg[0][\"lr\"]\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            vals = ds_engine.get_lr()\n",
        "            return vals[0] if isinstance(vals, (list, tuple)) and vals else float(\"nan\")\n",
        "        except Exception:\n",
        "            return float(\"nan\")\n",
        "    if optimizer is None: return float(\"nan\")\n",
        "    try:\n",
        "        return optimizer.param_groups[0][\"lr\"]\n",
        "    except Exception:\n",
        "        return float(\"nan\")\n",
        "\n",
        "def gpu_mem_gb():\n",
        "    if not torch.cuda.is_available(): return 0.0, 0.0\n",
        "    alloc = torch.cuda.memory_allocated() / (1024**3)\n",
        "    reserved = torch.cuda.memory_reserved() / (1024**3)\n",
        "    return alloc, reserved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_GrtgqdFGK9",
        "outputId": "72b250e4-6338-47cd-df53-84b0a35c22ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/utils/eval.py\n"
          ]
        }
      ],
      "source": [
        "# trainers/eval.py — 평가 함수\n",
        "%%writefile /content/drive/MyDrive/vla_project/utils/eval.py\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from losses import action_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model_like, loader, device, use_ds: bool):\n",
        "    \"\"\"\n",
        "    - model_like: DeepSpeed engine 또는 일반 nn.Module\n",
        "    - loader: data.py의 collate_vla가 반환한 배치(dict)용 DataLoader\n",
        "    \"\"\"\n",
        "    # eval 모드 전환 (파라미터는 module 쪽에서 관리)\n",
        "    module = model_like.module if use_ds else model_like\n",
        "    was_training = module.training\n",
        "    module.eval()\n",
        "\n",
        "    total, n = 0.0, 0\n",
        "    pbar = tqdm(loader, desc=\"[eval]\", leave=False)\n",
        "\n",
        "    for batch in pbar:\n",
        "        imgs   = batch[\"image\"].to(device, non_blocking=True)\n",
        "        texts  = batch.get(\"texts\", batch.get(\"text\"))\n",
        "        states = batch.get(\"state\")\n",
        "        acts   = batch.get(\"action\")\n",
        "\n",
        "        # 선택 텐서 처리\n",
        "        states = states.to(device, non_blocking=True) if states is not None else None\n",
        "        if acts is None:\n",
        "            # 손실 계산 불가 → 스킵\n",
        "            pbar.set_postfix(skip=\"no_action\")\n",
        "            continue\n",
        "        acts = acts.to(device, non_blocking=True)\n",
        "\n",
        "        # forward (states 유무에 따라)\n",
        "        if states is None:\n",
        "            pred = model_like(imgs, texts) if use_ds else module(imgs, texts)\n",
        "        else:\n",
        "            pred = model_like(imgs, texts, states) if use_ds else module(imgs, texts, states)\n",
        "\n",
        "        loss = action_loss(pred, acts)\n",
        "\n",
        "        bs = imgs.size(0)\n",
        "        total += loss.item() * bs\n",
        "        n     += bs\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", avg=f\"{(total/max(1,n)):.4f}\")\n",
        "\n",
        "    # 원래 모드 복귀\n",
        "    if was_training:\n",
        "        module.train()\n",
        "    else:\n",
        "        module.eval()\n",
        "\n",
        "    return total / max(1, n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8gcRWGMHavP",
        "outputId": "52617f45-f4f3-4dfb-85ba-343bbc3ff168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/utils/util.py\n"
          ]
        }
      ],
      "source": [
        "# utils/util.py — set_seed, save_checkpoint\n",
        "%%writefile /content/drive/MyDrive/vla_project/utils/util.py\n",
        "import os, io, random, tempfile\n",
        "from typing import Any, Dict, Union\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def _atomic_write_bytes(data: bytes, path: str) -> None:\n",
        "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
        "    dir_ = os.path.dirname(path) or \".\"\n",
        "    fd, tmppath = tempfile.mkstemp(prefix=\".tmp_\", dir=dir_)\n",
        "    try:\n",
        "        with os.fdopen(fd, \"wb\") as f:\n",
        "            f.write(data)\n",
        "            f.flush()\n",
        "            os.fsync(f.fileno())\n",
        "        os.replace(tmppath, path)  # atomic on POSIX\n",
        "    finally:\n",
        "        try:\n",
        "            if os.path.exists(tmppath):\n",
        "                os.remove(tmppath)\n",
        "        except Exception:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkytzgOUGYSB",
        "outputId": "2ecfec40-9cf1-4ae7-8745-f86b2f8a37e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/trainer.py\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# file: trainer.py\n",
        "# -----------------------------\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/trainer.py\n",
        "\n",
        "import os, json, time\n",
        "os.environ.setdefault(\"PYTHONUNBUFFERED\", \"1\")      # 즉시 flush\n",
        "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"3\")  # TF 로그 숨김\n",
        "\n",
        "import torch\n",
        "import deepspeed\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "from models.vla import VLA\n",
        "from losses import action_loss\n",
        "\n",
        "from util import set_seed , save_checkpoint\n",
        "from utils.progress import SmoothedValue, get_lr, gpu_mem_gb\n",
        "from utils.eval import evaluate\n",
        "from utils.vis import viz_episode\n",
        "\n",
        "from models.llm_func.lora_ft import LoraFTManager\n",
        "\n",
        "# 선택: 성능/안정성\n",
        "try:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "def train_loop(cfg):\n",
        "    set_seed(cfg.seed)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # ------------------------------\n",
        "    # Data\n",
        "    # ------------------------------\n",
        "    from data.data import make_dataloaders\n",
        "    train_loader, val_loader = make_dataloaders(cfg)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Model\n",
        "    # ------------------------------\n",
        "    model = VLA(\n",
        "        cfg.vision_backbone, cfg.vision_embed_dim,\n",
        "        cfg.text_model_name, cfg.text_embed_dim,\n",
        "        cfg.state_dim,\n",
        "        cfg.hidden_dim, cfg.action_dim,\n",
        "        fp16_text=cfg.amp, pad_token_str=cfg.pad_token_str,\n",
        "        text_max_len=cfg.text_max_len\n",
        "    )\n",
        "\n",
        "    # ------------------------------\n",
        "    # LoRA attach (텍스트 백본만 학습)\n",
        "    # ------------------------------\n",
        "    lora_mgr = LoraFTManager(model, task_type=\"FEATURE_EXTRACTION\")\n",
        "    model = lora_mgr.attach(\n",
        "        r=getattr(cfg, \"lora_r\", 8),\n",
        "        alpha=getattr(cfg, \"lora_alpha\", 32),\n",
        "        dropout=getattr(cfg, \"lora_dropout\", 0.1),\n",
        "        gradient_checkpointing=True,\n",
        "        print_report=True,\n",
        "    )\n",
        "\n",
        "    # ------------------------------\n",
        "    # Engine / Optimizer\n",
        "    # ------------------------------\n",
        "    use_ds   = bool(getattr(cfg, \"use_deepspeed\", False))\n",
        "    grad_clip = float(getattr(cfg, \"grad_clip\", 0.0) or 0.0)\n",
        "\n",
        "    if use_ds:\n",
        "        with open(cfg.deepspeed_config, 'r') as f:\n",
        "            ds_cfg = json.load(f)\n",
        "        ds_cfg.setdefault('train_batch_size', cfg.batch_size)\n",
        "        ds_cfg.setdefault('gradient_accumulation_steps', cfg.grad_accumulation_steps)\n",
        "\n",
        "        model_engine, optimizer, _, _ = deepspeed.initialize(\n",
        "            model=model,\n",
        "            model_parameters=[p for p in model.parameters() if p.requires_grad],\n",
        "            config=ds_cfg,\n",
        "        )\n",
        "        device = model_engine.device\n",
        "        scaler = None\n",
        "        forward_obj = model_engine\n",
        "    else:\n",
        "        model = model.to(device)\n",
        "        trainables = [p for p in model.parameters() if p.requires_grad]\n",
        "        optimizer = torch.optim.AdamW(trainables, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "        # torch.amp 권고 API로 변경(FutureWarning 해결)\n",
        "        scaler = GradScaler(enabled=cfg.amp, device=\"cuda\")\n",
        "        forward_obj = model\n",
        "\n",
        "    # ------------------------------\n",
        "    # Loop\n",
        "    # ------------------------------\n",
        "    global_step = 0\n",
        "    os.makedirs(cfg.ckpt_dir, exist_ok=True)\n",
        "\n",
        "    loss_avg = SmoothedValue()\n",
        "    t0 = time.time()\n",
        "    samples_processed = 0\n",
        "    last_eval_loss = None\n",
        "\n",
        "    steps_per_epoch = int(getattr(cfg, \"steps_per_epoch\", 2000))\n",
        "\n",
        "    for epoch in range(cfg.epochs):\n",
        "\n",
        "        it_start = time.time()\n",
        "\n",
        "        # 배치 타이밍 분해 측정 변수\n",
        "        load_t = fwd_t = bwd_t = 0.0\n",
        "\n",
        "        # enumerate로 인덱스, 강제 pbar.update(1)\n",
        "        for batch_idx, batch in enumerate(train_loader, 1):\n",
        "            t_load0 = time.time()\n",
        "            global_step += 1\n",
        "\n",
        "            texts = batch['text']\n",
        "            imgs = batch['image']\n",
        "            states = batch['state'].to(device)\n",
        "            rewards = batch['reward'].to(device)\n",
        "            discounts = batch['discount'].to(device)\n",
        "            is_first = batch['is_first'].to(device)\n",
        "            is_last = batch['is_last'].to(device)\n",
        "            is_term = batch['is_terminal'].to(device)\n",
        "            aux = batch['aux']\n",
        "\n",
        "            bsz = imgs.size(0) if hasattr(imgs, \"size\") else cfg.batch_size\n",
        "\n",
        "            imgs   = imgs.to(device, non_blocking=True)\n",
        "\n",
        "            acts = torch.tensor(batch['action'])\n",
        "            acts = acts.to(device, non_blocking=True)\n",
        "\n",
        "            t_load1 = time.time()\n",
        "\n",
        "            # fwd/bwd\n",
        "            if use_ds:\n",
        "                t_fwd0 = time.time()\n",
        "                pred = forward_obj(imgs, texts)\n",
        "                loss = action_loss(pred, acts)\n",
        "                t_fwd1 = time.time()\n",
        "                forward_obj.backward(loss)\n",
        "                forward_obj.step()\n",
        "                t_bwd1 = time.time()\n",
        "            else:\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                t_fwd0 = time.time()\n",
        "                # torch.amp 권고 API\n",
        "                with torch.amp.autocast(\"cuda\", enabled=cfg.amp):\n",
        "                    pred = forward_obj(imgs, texts , states)\n",
        "                    loss = action_loss(pred, acts)\n",
        "\n",
        "                t_fwd1 = time.time()\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                if grad_clip > 0:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(forward_obj.parameters(), grad_clip)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                t_bwd1 = time.time()\n",
        "\n",
        "            # 타이밍 누적\n",
        "            load_t += (t_load1 - t_load0)\n",
        "            fwd_t  += (t_fwd1 - t_fwd0)\n",
        "            bwd_t  += (t_bwd1 - t_fwd1)\n",
        "\n",
        "            # 진행도/속도\n",
        "            loss_avg.update(loss.item())\n",
        "            samples_processed += bsz\n",
        "            elapsed = max(1e-6, time.time() - t0)\n",
        "            steps_per_s   = global_step / elapsed\n",
        "            samples_per_s = samples_processed / elapsed\n",
        "            lr = get_lr(optimizer if not use_ds else None, forward_obj if use_ds else None)\n",
        "            alloc, reserved = gpu_mem_gb()\n",
        "\n",
        "            # 주기적 로그 (flush 강제)\n",
        "            if global_step % cfg.log_interval == 0:\n",
        "                lr_str = f\"{lr:.2e}\" if isinstance(lr, (float, int)) else str(lr)\n",
        "                print(\n",
        "                      f\"[log] ep {epoch} st {global_step} \"\n",
        "                      f\"loss={loss.item():.4f} avg={loss_avg.value:.4f} \"\n",
        "                      f\"lr={lr_str} \"\n",
        "                      f\"mem={alloc:.2f}/{reserved:.2f}GB \"\n",
        "                      f\"load={load_t/(batch_idx):.3f}s fwd={fwd_t/(batch_idx):.3f}s bwd={bwd_t/(batch_idx):.3f}s \"\n",
        "                      f\"sp_s={steps_per_s:.2f} samp_s={samples_per_s:.1f}\",\n",
        "                      flush=True,\n",
        "                    )\n",
        "\n",
        "            #if global_step % cfg.eval_interval == 0:\n",
        "            #    model_like = forward_obj\n",
        "            #    last_eval_loss = evaluate(model_like, val_loader, device, use_ds)\n",
        "            #    print(f\"[eval] global_step {global_step} | val_loss={last_eval_loss:.4f}\", flush=True)\n",
        "\n",
        "            if global_step % cfg.save_interval == 0:\n",
        "                target = forward_obj.module if use_ds else forward_obj\n",
        "                path = os.path.join(cfg.ckpt_dir, f\"vla_step{global_step}.pt\")\n",
        "                save_checkpoint(path, target.state_dict())\n",
        "                print(f\"[save] step {global_step} -> {path}\", flush=True)\n",
        "                # LoRA 어댑터만 별도 저장(옵션)\n",
        "                try:\n",
        "                    from peft import PeftModel\n",
        "                    if isinstance(target.text.backbone, PeftModel):\n",
        "                        target.text.backbone.save_pretrained(os.path.join(cfg.ckpt_dir, f\"lora_step{global_step}\"))\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            if batch_idx >= steps_per_epoch:\n",
        "              break\n",
        "\n",
        "        # 시각화\n",
        "\n",
        "\n",
        "        epoch_time = time.time() - it_start\n",
        "        if last_eval_loss is not None:\n",
        "            print(f\"[epoch] {epoch} done in {epoch_time:.1f}s | avg_loss={loss_avg.value:.4f} | last_val={last_eval_loss:.4f}\", flush=True)\n",
        "        else:\n",
        "            print(f\"[epoch] {epoch} done in {epoch_time:.1f}s | avg_loss={loss_avg.value:.4f}\", flush=True)\n",
        "\n",
        "    target = forward_obj.module if use_ds else forward_obj\n",
        "    path = os.path.join(cfg.ckpt_dir, \"vla_final.pt\")\n",
        "    save_checkpoint(path, target.state_dict())\n",
        "    print(f\"[done] Training finished. Saved: {path}\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM2ZH344NIns",
        "outputId": "88e26949-85dd-4109-fc8d-785ea40e335b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/train.py\n"
          ]
        }
      ],
      "source": [
        "# train.py\n",
        "\n",
        "%%writefile /content/drive/MyDrive/vla_project/train.py\n",
        "\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
        "\n",
        "# 메인은 얇게: 외부 모듈을 임포트해서 실행만 담당\n",
        "from trainer import train_loop\n",
        "\n",
        "# 필요시: config가 있다면 불러와 바로 실행 가능\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        from config import TrainConfig\n",
        "        cfg = TrainConfig()\n",
        "        train_loop(cfg)\n",
        "    except ImportError:\n",
        "        print(\"config.TrainConfig 를 찾을 수 없습니다. 외부에서 train_loop(cfg)로 호출하세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4znrjIYGOFjo"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# file: README_snippet.txt (참고)\n",
        "# -----------------------------\n",
        "# 1) 설치\n",
        "# pip install timm transformers accelerate safetensors deepspeed\n",
        "#\n",
        "# 2) ds_config.json 예시\n",
        "# {\n",
        "# \"train_batch_size\": 4,\n",
        "# \"gradient_accumulation_steps\": 2,\n",
        "# \"fp16\": {\"enabled\": true}, // 또는 \"bf16\": {\"enabled\": true}\n",
        "# \"zero_optimization\": {\"stage\": 2},\n",
        "# \"optimizer\": {\"type\": \"AdamW\", \"params\": {\"lr\": 3e-4, \"betas\": [0.9,0.999], \"eps\": 1e-8, \"weight_decay\": 1e-4}},\n",
        "# \"gradient_clipping\": 1.0,\n",
        "# \"steps_per_print\": 200\n",
        "# }\n",
        "#\n",
        "# 3) 단일 GPU 실행\n",
        "# python train.py --train_csv data/train.csv --val_csv data/val.csv --image_root . \\\n",
        "# --vision_backbone vit_base_patch14_dinov2 --text_model_name meta-llama/Llama-3-8B-Instruct \\\n",
        "# --img_size 224 --batch_size 4 --amp\n",
        "#\n",
        "# 4) DeepSpeed 실행 (예: 1~N GPU)\n",
        "# deepspeed train.py --deepspeed --deepspeed_config ds_config.json \\\n",
        "# --train_csv data/train.csv --val_csv data/val.csv --image_root . \\\n",
        "# --vision_backbone vit_base_patch14_dinov2 --text_model_name meta-llama/Llama-3-8B-Instruct \\\n",
        "# --img_size 224 --batch_size 4 --grad_accumulation_steps 2\n",
        "#\n",
        "# 5) 메모\n",
        "# - 이미지 I/O: DataLoader는 num_workers=0로 두고, collate에서 ThreadPoolExecutor로 배치 단위 병렬 디코드.\n",
        "# - CUDA 전송: pin_memory=True로 H2D 전송 가속, non_blocking=True 사용.\n",
        "# - DeepSpeed: model_engine(imgs, texts, states) 그대로 호출 → backward/step은 engine 메서드 사용.\n",
        "# - 체크포인트: DeepSpeed 모드에선 engine.module.state_dict() 저장."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMzystQHVe9Q",
        "outputId": "aa4abf10-b18e-43c2-8b7c-e18f908abfe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/vla_project/ds_config.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/vla_project/ds_config.json\n",
        "\n",
        "{\n",
        "  \"train_batch_size\": 4,\n",
        "  \"gradient_accumulation_steps\": 2,\n",
        "  \"fp16\": { \"enabled\": true },\n",
        "  \"zero_optimization\": { \"stage\": 2 },\n",
        "  \"optimizer\": {\n",
        "    \"type\": \"AdamW\",\n",
        "    \"params\": { \"lr\": 3e-4, \"betas\": [0.9, 0.999], \"eps\": 1e-8, \"weight_decay\": 1e-4 }\n",
        "  },\n",
        "  \"gradient_clipping\": 1.0,\n",
        "  \"steps_per_print\": 200\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEpe-rjHVlF6",
        "outputId": "79d65a96-c9d6-4a53-ac73-39567e42c2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762303963.741051    1433 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762303963.747641    1433 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762303963.764479    1433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762303963.764511    1433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762303963.764515    1433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762303963.764517    1433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[INFO] reasoning entries: 2255552\n",
            "[INFO] reasoning entries: 2255552\n",
            "model.safetensors: 100% 346M/346M [00:01<00:00, 220MB/s]\n",
            "tokenizer_config.json: 100% 51.0k/51.0k [00:00<00:00, 12.9MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 15.5MB/s]\n",
            "special_tokens_map.json: 100% 73.0/73.0 [00:00<00:00, 479kB/s]\n",
            "config.json: 100% 654/654 [00:00<00:00, 4.48MB/s]\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 87.7MB/s]\n",
            "Fetching 4 files:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   0% 500k/5.00G [00:01<3:24:31, 407kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   0% 816k/4.92G [00:01<2:25:54, 561kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   1% 67.6M/5.00G [00:01<01:23, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   4% 202M/5.00G [00:01<00:25, 189MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   8% 403M/5.00G [00:01<00:11, 414MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:   1% 14.6M/1.17G [00:01<02:31, 7.59MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  11% 537M/5.00G [00:01<00:08, 506MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   1% 67.8M/4.92G [00:02<01:57, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 18.8k/4.98G [00:02<155:51:26, 8.87kB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:   7% 81.7M/1.17G [00:02<00:22, 47.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  16% 805M/5.00G [00:02<00:05, 761MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  13% 149M/1.17G [00:02<00:10, 95.3MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 78.6k/4.98G [00:02<34:13:46, 40.4kB/s] \u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  19% 216M/1.17G [00:02<00:06, 150MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  19% 940M/5.00G [00:02<00:06, 644MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   3% 136M/4.92G [00:02<01:05, 73.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  30% 351M/1.17G [00:02<00:02, 281MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 101k/4.98G [00:02<27:36:06, 50.1kB/s] \u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  42% 489M/1.17G [00:02<00:01, 367MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 118k/4.98G [00:02<26:45:45, 51.7kB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   4% 203M/4.92G [00:02<00:50, 93.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 143k/4.98G [00:03<21:35:01, 64.0kB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   8% 405M/4.92G [00:03<00:18, 242MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 187k/4.98G [00:03<14:18:43, 96.6kB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  11% 539M/4.92G [00:03<00:13, 324MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  48% 565M/1.17G [00:03<00:02, 264MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  54% 632M/1.17G [00:03<00:01, 297MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  12% 605M/4.92G [00:03<00:13, 316MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  21% 1.07G/5.00G [00:03<00:13, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  14% 672M/4.92G [00:03<00:12, 346MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  60% 699M/1.17G [00:03<00:01, 280MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 206k/4.98G [00:03<18:42:39, 73.9kB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 219k/4.98G [00:04<22:52:06, 60.4kB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  18% 873M/4.92G [00:04<00:11, 356MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 442k/4.98G [00:04<4:48:17, 288kB/s]  \u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  71% 833M/1.17G [00:04<00:01, 265MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  23% 1.14G/5.00G [00:04<00:18, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  77% 900M/1.17G [00:04<00:01, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  31% 1.54G/5.00G [00:04<00:09, 358MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  20% 1.01G/4.92G [00:04<00:14, 277MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 514k/4.98G [00:04<7:02:54, 196kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  32% 1.61G/5.00G [00:05<00:12, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  22% 1.07G/4.92G [00:05<00:17, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 568k/4.98G [00:05<9:03:17, 153kB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  89% 1.03G/1.17G [00:05<00:00, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  23% 1.14G/4.92G [00:06<00:22, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  34% 1.68G/5.00G [00:06<00:15, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors:  94% 1.10G/1.17G [00:06<00:00, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 609k/4.98G [00:06<12:17:03, 113kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  35% 1.75G/5.00G [00:06<00:17, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  25% 1.21G/4.92G [00:06<00:25, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 8.93M/4.98G [00:07<21:39, 3.82MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  26% 1.28G/4.92G [00:07<00:22, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  36% 1.81G/5.00G [00:07<00:17, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:07<00:00, 158MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  27% 1.34G/4.92G [00:07<00:19, 183MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  29% 1.41G/4.92G [00:07<00:15, 224MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  30% 1.48G/4.92G [00:07<00:15, 224MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  33% 1.61G/4.92G [00:08<00:11, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  39% 1.95G/5.00G [00:08<00:20, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  35% 1.75G/4.92G [00:08<00:09, 328MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  42% 2.08G/5.00G [00:08<00:15, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  37% 1.81G/4.92G [00:08<00:10, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  38% 1.88G/4.92G [00:09<00:11, 258MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  43% 2.15G/5.00G [00:09<00:18, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  41% 2.01G/4.92G [00:09<00:11, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 76.1M/4.98G [00:09<04:33, 17.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  42% 2.08G/4.92G [00:11<00:29, 96.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  44% 2.22G/5.00G [00:11<00:35, 77.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  45% 2.21G/4.92G [00:12<00:17, 151MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  47% 2.35G/5.00G [00:12<00:21, 122MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  48% 2.35G/4.92G [00:12<00:11, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  48% 2.42G/5.00G [00:12<00:17, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  51% 2.48G/4.92G [00:12<00:08, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  50% 2.49G/5.00G [00:12<00:14, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  51% 2.55G/5.00G [00:12<00:13, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  53% 2.62G/4.92G [00:12<00:08, 275MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  52% 2.62G/5.00G [00:12<00:11, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   2% 77.4M/4.98G [00:13<09:39, 8.46MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  54% 2.69G/5.00G [00:13<00:11, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  56% 2.75G/4.92G [00:13<00:08, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  55% 2.75G/5.00G [00:13<00:12, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 144M/4.98G [00:13<03:55, 20.5MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  57% 2.82G/4.92G [00:13<00:09, 230MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  56% 2.82G/5.00G [00:16<00:30, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  59% 2.89G/4.92G [00:16<00:20, 99.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  63% 3.09G/4.92G [00:16<00:10, 178MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  66% 3.22G/4.92G [00:16<00:06, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  68% 3.36G/4.92G [00:16<00:05, 304MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  60% 3.02G/5.00G [00:16<00:16, 122MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  71% 3.49G/4.92G [00:16<00:04, 298MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  66% 3.29G/5.00G [00:17<00:07, 222MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  67% 3.36G/5.00G [00:17<00:07, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  72% 3.56G/4.92G [00:17<00:05, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  68% 3.42G/5.00G [00:17<00:07, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  74% 3.62G/4.92G [00:17<00:05, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  70% 3.49G/5.00G [00:17<00:06, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  76% 3.71G/4.92G [00:20<00:12, 93.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  71% 3.56G/5.00G [00:20<00:16, 89.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  78% 3.85G/4.92G [00:20<00:07, 142MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  74% 3.69G/5.00G [00:20<00:09, 138MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  81% 3.98G/4.92G [00:20<00:04, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  77% 3.83G/5.00G [00:20<00:05, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  84% 4.11G/4.92G [00:20<00:02, 285MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  79% 3.96G/5.00G [00:20<00:03, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  86% 4.25G/4.92G [00:21<00:02, 238MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  82% 4.09G/5.00G [00:21<00:03, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   4% 205M/4.98G [00:21<06:51, 11.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  84% 4.20G/5.00G [00:22<00:04, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 272M/4.98G [00:24<05:09, 15.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  89% 4.38G/4.92G [00:24<00:05, 99.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  85% 4.26G/5.00G [00:24<00:07, 95.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 493M/4.98G [00:24<01:41, 44.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  92% 4.51G/4.92G [00:24<00:02, 138MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  88% 4.40G/5.00G [00:24<00:04, 141MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 559M/4.98G [00:24<01:20, 55.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  91% 4.53G/5.00G [00:24<00:02, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  95% 4.65G/4.92G [00:24<00:01, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  92% 4.60G/5.00G [00:24<00:01, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  93% 4.66G/5.00G [00:25<00:01, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 618M/4.98G [00:25<01:14, 58.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  95% 4.73G/5.00G [00:25<00:01, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  97% 4.78G/4.92G [00:25<00:00, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 685M/4.98G [00:25<01:02, 69.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  99% 4.85G/4.92G [00:26<00:00, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 782M/4.98G [00:26<00:44, 94.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 819M/4.98G [00:28<01:16, 54.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  96% 4.80G/5.00G [00:28<00:02, 68.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 953M/4.98G [00:28<00:42, 95.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 1.10G/4.98G [00:28<00:25, 151MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.29G/4.98G [00:28<00:14, 248MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28% 1.41G/4.98G [00:28<00:11, 320MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.58G/4.98G [00:29<00:07, 425MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.72G/4.98G [00:29<00:09, 339MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  97% 4.87G/5.00G [00:29<00:02, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  37% 1.82G/4.98G [00:30<00:10, 314MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.89G/4.98G [00:30<00:09, 318MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.02G/4.98G [00:30<00:08, 358MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.09G/4.98G [00:30<00:07, 378MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44% 2.19G/4.98G [00:30<00:06, 427MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.31G/4.98G [00:31<00:06, 416MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:31<00:00, 157MB/s] \n",
            "\n",
            "model-00001-of-00004.safetensors:  48% 2.38G/4.98G [00:31<00:08, 310MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.47G/4.98G [00:31<00:06, 364MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52% 2.57G/4.98G [00:32<00:10, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.65G/4.98G [00:32<00:08, 286MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.98G/4.98G [00:32<00:03, 613MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  99% 4.93G/5.00G [00:33<00:01, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.11G/4.98G [00:33<00:05, 362MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:33<00:00, 148MB/s] \n",
            "\n",
            "model-00001-of-00004.safetensors:  65% 3.24G/4.98G [00:34<00:05, 342MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.38G/4.98G [00:34<00:04, 395MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.47G/4.98G [00:34<00:03, 388MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 3.54G/4.98G [00:34<00:03, 363MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.60G/4.98G [00:34<00:03, 350MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.67G/4.98G [00:35<00:03, 365MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75% 3.74G/4.98G [00:35<00:03, 374MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76% 3.80G/4.98G [00:35<00:03, 370MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.86G/4.98G [00:35<00:03, 370MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79% 3.95G/4.98G [00:35<00:02, 377MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 4.01G/4.98G [00:36<00:02, 376MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.08G/4.98G [00:36<00:02, 335MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.17G/4.98G [00:36<00:02, 349MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.24G/4.98G [00:36<00:02, 332MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.31G/4.98G [00:36<00:01, 347MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88% 4.37G/4.98G [00:37<00:01, 368MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.44G/4.98G [00:37<00:01, 382MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.51G/4.98G [00:37<00:01, 395MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 4.64G/4.98G [00:37<00:00, 504MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.71G/4.98G [00:37<00:00, 444MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.78G/4.98G [00:37<00:00, 423MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:38<00:00, 130MB/s]\n",
            "Fetching 4 files: 100% 4/4 [00:38<00:00,  9.60s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [00:03<00:00,  1.21it/s]\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "trainable params: 20,971,520 || all params: 7,525,900,288 || trainable%: 0.2787\n",
            "I0000 00:00:1762304091.013692    1433 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 64335 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:05.0, compute capability: 8.0\n",
            "/content/drive/MyDrive/vla_project/trainer.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  acts = torch.tensor(batch['action'])\n",
            "[DBG/TEXT] input_ids=(32, 18)\n",
            "[log] ep 0 st 50 loss=0.0553 avg=0.0768 lr=3.00e-04 mem=14.75/20.04GB load=0.024s fwd=0.258s bwd=0.186s sp_s=0.31 samp_s=10.0\n",
            "[log] ep 0 st 100 loss=0.0456 avg=0.0549 lr=3.00e-04 mem=14.75/20.22GB load=0.024s fwd=0.230s bwd=0.178s sp_s=0.52 samp_s=16.7\n",
            "[log] ep 0 st 150 loss=0.0350 avg=0.0446 lr=3.00e-04 mem=14.75/20.22GB load=0.024s fwd=0.221s bwd=0.176s sp_s=0.67 samp_s=21.4\n",
            "[log] ep 0 st 200 loss=0.0497 avg=0.0389 lr=3.00e-04 mem=14.75/20.22GB load=0.024s fwd=0.217s bwd=0.175s sp_s=0.78 samp_s=25.0\n",
            "[log] ep 0 st 250 loss=0.0333 avg=0.0361 lr=3.00e-04 mem=14.75/20.22GB load=0.024s fwd=0.214s bwd=0.176s sp_s=0.87 samp_s=27.7\n",
            "[log] ep 0 st 300 loss=0.0395 avg=0.0369 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.213s bwd=0.176s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 0 st 350 loss=0.0525 avg=0.0366 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.99 samp_s=31.7\n",
            "[log] ep 0 st 400 loss=0.0389 avg=0.0371 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.210s bwd=0.175s sp_s=1.04 samp_s=33.2\n",
            "[log] ep 0 st 450 loss=0.0395 avg=0.0410 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.210s bwd=0.174s sp_s=1.08 samp_s=34.4\n",
            "[log] ep 0 st 500 loss=0.0355 avg=0.0391 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.209s bwd=0.174s sp_s=1.11 samp_s=35.5\n",
            "[log] ep 0 st 550 loss=0.0332 avg=0.0392 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.209s bwd=0.174s sp_s=1.14 samp_s=36.4\n",
            "[log] ep 0 st 600 loss=0.0543 avg=0.0366 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.208s bwd=0.174s sp_s=1.17 samp_s=37.3\n",
            "[log] ep 0 st 650 loss=0.0271 avg=0.0374 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.208s bwd=0.174s sp_s=1.19 samp_s=38.0\n",
            "[log] ep 0 st 700 loss=0.0314 avg=0.0372 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.207s bwd=0.174s sp_s=1.21 samp_s=38.7\n",
            "[log] ep 0 st 750 loss=0.0310 avg=0.0370 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.207s bwd=0.174s sp_s=1.23 samp_s=39.2\n",
            "[log] ep 0 st 800 loss=0.0336 avg=0.0415 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.207s bwd=0.174s sp_s=1.24 samp_s=39.8\n",
            "[log] ep 0 st 850 loss=0.0353 avg=0.0420 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.207s bwd=0.174s sp_s=1.26 samp_s=40.2\n",
            "[log] ep 0 st 900 loss=0.0552 avg=0.0447 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.207s bwd=0.174s sp_s=1.27 samp_s=40.7\n",
            "[log] ep 0 st 950 loss=0.0320 avg=0.0393 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.207s bwd=0.174s sp_s=1.28 samp_s=41.0\n",
            "[log] ep 0 st 1000 loss=0.0345 avg=0.0386 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.207s bwd=0.174s sp_s=1.29 samp_s=41.3\n",
            "[save] step 1000 -> checkpoints/vla_step1000.pt\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "[log] ep 0 st 1050 loss=0.0374 avg=0.0391 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 0 st 1100 loss=0.0254 avg=0.0360 lr=3.00e-04 mem=14.75/20.81GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 0 st 1150 loss=0.0380 avg=0.0375 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.175s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 0 st 1200 loss=0.0503 avg=0.0358 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.175s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 0 st 1250 loss=0.0351 avg=0.0364 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=0.99 samp_s=31.7\n",
            "[log] ep 0 st 1300 loss=0.0370 avg=0.0375 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.00 samp_s=32.1\n",
            "[log] ep 0 st 1350 loss=0.0366 avg=0.0359 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.02 samp_s=32.5\n",
            "[log] ep 0 st 1400 loss=0.0331 avg=0.0356 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.03 samp_s=32.9\n",
            "[log] ep 0 st 1450 loss=0.0302 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.04 samp_s=33.3\n",
            "[log] ep 0 st 1500 loss=0.0338 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.05 samp_s=33.6\n",
            "[log] ep 0 st 1550 loss=0.0342 avg=0.0354 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.06 samp_s=34.0\n",
            "[log] ep 0 st 1600 loss=0.0345 avg=0.0362 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.07 samp_s=34.3\n",
            "[log] ep 0 st 1650 loss=0.0340 avg=0.0352 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.176s sp_s=1.08 samp_s=34.6\n",
            "[log] ep 0 st 1700 loss=0.0387 avg=0.0346 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=1.09 samp_s=34.9\n",
            "[log] ep 0 st 1750 loss=0.0297 avg=0.0346 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=1.10 samp_s=35.2\n",
            "[log] ep 0 st 1800 loss=0.0391 avg=0.0353 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=1.11 samp_s=35.5\n",
            "[log] ep 0 st 1850 loss=0.0321 avg=0.0363 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=1.12 samp_s=35.8\n",
            "[log] ep 0 st 1900 loss=0.0346 avg=0.0354 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=1.13 samp_s=36.1\n",
            "[log] ep 0 st 1950 loss=0.0205 avg=0.0352 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=1.13 samp_s=36.3\n",
            "[log] ep 0 st 2000 loss=0.0415 avg=0.0365 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.176s sp_s=1.14 samp_s=36.5\n",
            "[save] step 2000 -> checkpoints/vla_step2000.pt\n",
            "[epoch] 0 done in 2111.9s | avg_loss=0.0365\n",
            "[log] ep 1 st 2050 loss=0.0344 avg=0.0357 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.178s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 1 st 2100 loss=0.0367 avg=0.0356 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.204s bwd=0.176s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 1 st 2150 loss=0.0336 avg=0.0360 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.175s sp_s=0.97 samp_s=31.1\n",
            "[log] ep 1 st 2200 loss=0.0459 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 1 st 2250 loss=0.0278 avg=0.0328 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 1 st 2300 loss=0.0343 avg=0.0342 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.178s sp_s=1.00 samp_s=31.8\n",
            "[log] ep 1 st 2350 loss=0.0343 avg=0.0353 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.178s sp_s=1.00 samp_s=32.1\n",
            "[log] ep 1 st 2400 loss=0.0501 avg=0.0360 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.178s sp_s=1.01 samp_s=32.3\n",
            "[log] ep 1 st 2450 loss=0.0390 avg=0.0347 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.179s sp_s=1.02 samp_s=32.5\n",
            "[log] ep 1 st 2500 loss=0.0351 avg=0.0344 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.179s sp_s=1.02 samp_s=32.7\n",
            "[log] ep 1 st 2550 loss=0.0332 avg=0.0350 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.181s sp_s=1.03 samp_s=32.9\n",
            "[log] ep 1 st 2600 loss=0.0431 avg=0.0349 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.182s sp_s=1.03 samp_s=33.1\n",
            "[log] ep 1 st 2650 loss=0.0284 avg=0.0356 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.182s sp_s=1.04 samp_s=33.3\n",
            "[log] ep 1 st 2700 loss=0.0312 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.181s sp_s=1.05 samp_s=33.5\n",
            "[log] ep 1 st 2750 loss=0.0288 avg=0.0350 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.181s sp_s=1.05 samp_s=33.7\n",
            "[log] ep 1 st 2800 loss=0.0282 avg=0.0367 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.06 samp_s=33.9\n",
            "[log] ep 1 st 2850 loss=0.0280 avg=0.0344 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.180s sp_s=1.06 samp_s=34.1\n",
            "[log] ep 1 st 2900 loss=0.0378 avg=0.0346 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.180s sp_s=1.07 samp_s=34.2\n",
            "[log] ep 1 st 2950 loss=0.0320 avg=0.0337 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.180s sp_s=1.08 samp_s=34.4\n",
            "[log] ep 1 st 3000 loss=0.0305 avg=0.0341 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.180s sp_s=1.08 samp_s=34.6\n",
            "[save] step 3000 -> checkpoints/vla_step3000.pt\n",
            "[log] ep 1 st 3050 loss=0.0357 avg=0.0349 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.179s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 1 st 3100 loss=0.0260 avg=0.0337 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.179s sp_s=0.99 samp_s=31.8\n",
            "[log] ep 1 st 3150 loss=0.0369 avg=0.0349 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.00 samp_s=31.9\n",
            "[log] ep 1 st 3200 loss=0.0411 avg=0.0343 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.00 samp_s=32.1\n",
            "[log] ep 1 st 3250 loss=0.0348 avg=0.0341 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.181s sp_s=1.01 samp_s=32.2\n",
            "[log] ep 1 st 3300 loss=0.0370 avg=0.0354 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.181s sp_s=1.01 samp_s=32.4\n",
            "[log] ep 1 st 3350 loss=0.0361 avg=0.0343 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.181s sp_s=1.02 samp_s=32.5\n",
            "[log] ep 1 st 3400 loss=0.0321 avg=0.0339 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.181s sp_s=1.02 samp_s=32.7\n",
            "[log] ep 1 st 3450 loss=0.0245 avg=0.0332 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.181s sp_s=1.03 samp_s=32.8\n",
            "[log] ep 1 st 3500 loss=0.0337 avg=0.0336 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.180s sp_s=1.03 samp_s=33.0\n",
            "[log] ep 1 st 3550 loss=0.0342 avg=0.0341 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.04 samp_s=33.2\n",
            "[log] ep 1 st 3600 loss=0.0337 avg=0.0350 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.04 samp_s=33.3\n",
            "[log] ep 1 st 3650 loss=0.0345 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.05 samp_s=33.5\n",
            "[log] ep 1 st 3700 loss=0.0365 avg=0.0342 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.05 samp_s=33.6\n",
            "[log] ep 1 st 3750 loss=0.0305 avg=0.0339 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.05 samp_s=33.7\n",
            "[log] ep 1 st 3800 loss=0.0338 avg=0.0343 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.180s sp_s=1.06 samp_s=33.9\n",
            "[log] ep 1 st 3850 loss=0.0299 avg=0.0355 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.179s sp_s=1.06 samp_s=34.0\n",
            "[log] ep 1 st 3900 loss=0.0343 avg=0.0344 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.179s sp_s=1.07 samp_s=34.1\n",
            "[log] ep 1 st 3950 loss=0.0202 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.179s sp_s=1.07 samp_s=34.3\n",
            "[log] ep 1 st 4000 loss=0.0402 avg=0.0353 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.179s sp_s=1.08 samp_s=34.4\n",
            "[save] step 4000 -> checkpoints/vla_step4000.pt\n",
            "[epoch] 1 done in 2011.6s | avg_loss=0.0353\n",
            "[log] ep 2 st 4050 loss=0.0259 avg=0.0344 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.181s sp_s=0.97 samp_s=31.1\n",
            "[log] ep 2 st 4100 loss=0.0352 avg=0.0346 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.190s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 2 st 4150 loss=0.0319 avg=0.0347 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.186s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 2 st 4200 loss=0.0431 avg=0.0335 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.184s sp_s=0.98 samp_s=31.5\n",
            "[log] ep 2 st 4250 loss=0.0269 avg=0.0320 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.182s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 2 st 4300 loss=0.0355 avg=0.0336 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.181s sp_s=0.99 samp_s=31.8\n",
            "[log] ep 2 st 4350 loss=0.0352 avg=0.0347 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.180s sp_s=1.00 samp_s=31.9\n",
            "[log] ep 2 st 4400 loss=0.0482 avg=0.0353 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.179s sp_s=1.00 samp_s=32.0\n",
            "[log] ep 2 st 4450 loss=0.0398 avg=0.0339 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.179s sp_s=1.00 samp_s=32.2\n",
            "[log] ep 2 st 4500 loss=0.0331 avg=0.0335 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.179s sp_s=1.01 samp_s=32.3\n",
            "[log] ep 2 st 4550 loss=0.0328 avg=0.0340 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.178s sp_s=1.01 samp_s=32.4\n",
            "[log] ep 2 st 4600 loss=0.0413 avg=0.0337 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.178s sp_s=1.02 samp_s=32.5\n",
            "[log] ep 2 st 4650 loss=0.0269 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.178s sp_s=1.02 samp_s=32.6\n",
            "[log] ep 2 st 4700 loss=0.0284 avg=0.0339 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.178s sp_s=1.02 samp_s=32.8\n",
            "[log] ep 2 st 4750 loss=0.0274 avg=0.0338 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.178s sp_s=1.03 samp_s=32.9\n",
            "[log] ep 2 st 4800 loss=0.0274 avg=0.0354 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.178s sp_s=1.03 samp_s=33.0\n",
            "[log] ep 2 st 4850 loss=0.0284 avg=0.0337 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.03 samp_s=33.1\n",
            "[log] ep 2 st 4900 loss=0.0249 avg=0.0336 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.04 samp_s=33.2\n",
            "[log] ep 2 st 4950 loss=0.0313 avg=0.0333 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.04 samp_s=33.3\n",
            "[log] ep 2 st 5000 loss=0.0297 avg=0.0337 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.05 samp_s=33.4\n",
            "[save] step 5000 -> checkpoints/vla_step5000.pt\n",
            "[log] ep 2 st 5050 loss=0.0301 avg=0.0339 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 2 st 5100 loss=0.0244 avg=0.0332 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 2 st 5150 loss=0.0378 avg=0.0345 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=0.98 samp_s=31.5\n",
            "[log] ep 2 st 5200 loss=0.0418 avg=0.0339 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 2 st 5250 loss=0.0347 avg=0.0337 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=0.99 samp_s=31.7\n",
            "[log] ep 2 st 5300 loss=0.0379 avg=0.0346 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=0.99 samp_s=31.8\n",
            "[log] ep 2 st 5350 loss=0.0380 avg=0.0335 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.00 samp_s=31.9\n",
            "[log] ep 2 st 5400 loss=0.0325 avg=0.0335 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.00 samp_s=32.0\n",
            "[log] ep 2 st 5450 loss=0.0231 avg=0.0328 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.00 samp_s=32.1\n",
            "[log] ep 2 st 5500 loss=0.0340 avg=0.0332 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.01 samp_s=32.2\n",
            "[log] ep 2 st 5550 loss=0.0329 avg=0.0336 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.01 samp_s=32.3\n",
            "[log] ep 2 st 5600 loss=0.0328 avg=0.0347 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.01 samp_s=32.4\n",
            "[log] ep 2 st 5650 loss=0.0330 avg=0.0340 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.02 samp_s=32.5\n",
            "[log] ep 2 st 5700 loss=0.0376 avg=0.0334 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.02 samp_s=32.6\n",
            "[log] ep 2 st 5750 loss=0.0299 avg=0.0329 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.02 samp_s=32.7\n",
            "[log] ep 2 st 5800 loss=0.0347 avg=0.0335 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.03 samp_s=32.8\n",
            "[log] ep 2 st 5850 loss=0.0287 avg=0.0349 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.03 samp_s=32.9\n",
            "[log] ep 2 st 5900 loss=0.0338 avg=0.0339 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.03 samp_s=33.0\n",
            "[log] ep 2 st 5950 loss=0.0194 avg=0.0342 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.177s sp_s=1.03 samp_s=33.1\n",
            "[log] ep 2 st 6000 loss=0.0446 avg=0.0348 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=1.04 samp_s=33.2\n",
            "[save] step 6000 -> checkpoints/vla_step6000.pt\n",
            "[epoch] 2 done in 2028.4s | avg_loss=0.0348\n",
            "[log] ep 3 st 6050 loss=0.0262 avg=0.0335 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.178s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 3 st 6100 loss=0.0324 avg=0.0337 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 3 st 6150 loss=0.0323 avg=0.0340 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.98 samp_s=31.5\n",
            "[log] ep 3 st 6200 loss=0.0422 avg=0.0330 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.99 samp_s=31.5\n",
            "[log] ep 3 st 6250 loss=0.0252 avg=0.0316 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 3 st 6300 loss=0.0343 avg=0.0332 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.99 samp_s=31.7\n",
            "[log] ep 3 st 6350 loss=0.0346 avg=0.0342 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=0.99 samp_s=31.8\n",
            "[log] ep 3 st 6400 loss=0.0480 avg=0.0350 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=1.00 samp_s=31.9\n",
            "[log] ep 3 st 6450 loss=0.0379 avg=0.0334 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=1.00 samp_s=32.0\n",
            "[log] ep 3 st 6500 loss=0.0328 avg=0.0331 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=1.00 samp_s=32.1\n",
            "[log] ep 3 st 6550 loss=0.0331 avg=0.0331 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=1.01 samp_s=32.2\n",
            "[log] ep 3 st 6600 loss=0.0407 avg=0.0329 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.176s sp_s=1.01 samp_s=32.2\n",
            "[log] ep 3 st 6650 loss=0.0278 avg=0.0340 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.177s sp_s=1.01 samp_s=32.3\n",
            "[log] ep 3 st 6700 loss=0.0266 avg=0.0332 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.177s sp_s=1.01 samp_s=32.4\n",
            "[log] ep 3 st 6750 loss=0.0264 avg=0.0332 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.177s sp_s=1.02 samp_s=32.5\n",
            "[log] ep 3 st 6800 loss=0.0267 avg=0.0347 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.177s sp_s=1.02 samp_s=32.6\n",
            "[log] ep 3 st 6850 loss=0.0265 avg=0.0331 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.177s sp_s=1.02 samp_s=32.6\n",
            "[log] ep 3 st 6900 loss=0.0287 avg=0.0331 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.177s sp_s=1.02 samp_s=32.7\n",
            "[log] ep 3 st 6950 loss=0.0315 avg=0.0327 lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.177s sp_s=1.03 samp_s=32.8\n",
            "[log] ep 3 st 7000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=1.03 samp_s=32.9\n",
            "[save] step 7000 -> checkpoints/vla_step7000.pt\n",
            "[log] ep 3 st 7050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 3 st 7100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.96 samp_s=30.9\n",
            "[log] ep 3 st 7150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.176s sp_s=0.97 samp_s=30.9\n",
            "[log] ep 3 st 7200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.175s sp_s=0.97 samp_s=31.0\n",
            "[log] ep 3 st 7250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.175s sp_s=0.97 samp_s=31.1\n",
            "[log] ep 3 st 7300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.175s sp_s=0.97 samp_s=31.2\n",
            "[log] ep 3 st 7350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.175s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 3 st 7400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 3 st 7450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 3 st 7500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.98 samp_s=31.5\n",
            "[log] ep 3 st 7550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 3 st 7600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 3 st 7650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.99 samp_s=31.7\n",
            "[log] ep 3 st 7700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=0.99 samp_s=31.8\n",
            "[log] ep 3 st 7750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=1.00 samp_s=31.9\n",
            "[log] ep 3 st 7800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.174s sp_s=1.00 samp_s=31.9\n",
            "[log] ep 3 st 7850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.173s sp_s=1.00 samp_s=32.0\n",
            "[log] ep 3 st 7900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.173s sp_s=1.00 samp_s=32.1\n",
            "[log] ep 3 st 7950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.173s sp_s=1.00 samp_s=32.1\n",
            "[log] ep 3 st 8000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.173s sp_s=1.01 samp_s=32.2\n",
            "[save] step 8000 -> checkpoints/vla_step8000.pt\n",
            "[epoch] 3 done in 2263.2s | avg_loss=nan\n",
            "[log] ep 4 st 8050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 4 st 8100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 4 st 8150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.171s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 4 st 8200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 4 st 8250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.171s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 4 st 8300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 4 st 8350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.96 samp_s=30.9\n",
            "[log] ep 4 st 8400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.97 samp_s=30.9\n",
            "[log] ep 4 st 8450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.169s sp_s=0.97 samp_s=31.0\n",
            "[log] ep 4 st 8500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.169s sp_s=0.97 samp_s=31.0\n",
            "[log] ep 4 st 8550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.97 samp_s=31.1\n",
            "[log] ep 4 st 8600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.97 samp_s=31.2\n",
            "[log] ep 4 st 8650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.98 samp_s=31.2\n",
            "[log] ep 4 st 8700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 4 st 8750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 4 st 8800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 4 st 8850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.98 samp_s=31.5\n",
            "[log] ep 4 st 8900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.99 samp_s=31.5\n",
            "[log] ep 4 st 8950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 4 st 9000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.99 samp_s=31.6\n",
            "[save] step 9000 -> checkpoints/vla_step9000.pt\n",
            "[log] ep 4 st 9050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 4 st 9100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 4 st 9150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.168s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 4 st 9200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.169s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 4 st 9250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.169s sp_s=0.97 samp_s=30.9\n",
            "[log] ep 4 st 9300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.169s sp_s=0.97 samp_s=30.9\n",
            "[log] ep 4 st 9350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.205s bwd=0.169s sp_s=0.97 samp_s=31.0\n",
            "[log] ep 4 st 9400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.97 samp_s=31.1\n",
            "[log] ep 4 st 9450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.97 samp_s=31.1\n",
            "[log] ep 4 st 9500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.97 samp_s=31.2\n",
            "[log] ep 4 st 9550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 4 st 9600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.98 samp_s=31.3\n",
            "[log] ep 4 st 9650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 4 st 9700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.98 samp_s=31.4\n",
            "[log] ep 4 st 9750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.98 samp_s=31.5\n",
            "[log] ep 4 st 9800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.99 samp_s=31.5\n",
            "[log] ep 4 st 9850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.99 samp_s=31.6\n",
            "[log] ep 4 st 9900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.99 samp_s=31.7\n",
            "[log] ep 4 st 9950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.99 samp_s=31.7\n",
            "[log] ep 4 st 10000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.99 samp_s=31.8\n",
            "[save] step 10000 -> checkpoints/vla_step10000.pt\n",
            "[epoch] 4 done in 2174.6s | avg_loss=nan\n",
            "[log] ep 5 st 10050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.176s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 5 st 10100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.172s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 5 st 10150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=29.9\n",
            "[log] ep 5 st 10200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 5 st 10250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 5 st 10300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 5 st 10350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 5 st 10400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 5 st 10450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 5 st 10500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 5 st 10550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 5 st 10600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 5 st 10650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 5 st 10700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 5 st 10750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 5 st 10800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.170s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 5 st 10850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 5 st 10900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 5 st 10950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 5 st 11000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.97 samp_s=30.9\n",
            "[save] step 11000 -> checkpoints/vla_step11000.pt\n",
            "[log] ep 5 st 11050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 5 st 11100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 5 st 11150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 5 st 11200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 5 st 11250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.95 samp_s=30.2\n",
            "[log] ep 5 st 11300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 5 st 11350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 5 st 11400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 5 st 11450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.206s bwd=0.169s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 5 st 11500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.169s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 5 st 11550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.169s sp_s=0.95 samp_s=30.6\n",
            "[log] ep 5 st 11600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.169s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 5 st 11650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 5 st 11700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 5 st 11750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 5 st 11800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.96 samp_s=30.8\n",
            "[log] ep 5 st 11850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.96 samp_s=30.9\n",
            "[log] ep 5 st 11900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.97 samp_s=30.9\n",
            "[log] ep 5 st 11950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.97 samp_s=30.9\n",
            "[log] ep 5 st 12000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.170s sp_s=0.97 samp_s=31.0\n",
            "[save] step 12000 -> checkpoints/vla_step12000.pt\n",
            "[epoch] 5 done in 2146.9s | avg_loss=nan\n",
            "[log] ep 6 st 12050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.176s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 6 st 12100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.174s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 6 st 12150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 6 st 12200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 6 st 12250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 6 st 12300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 6 st 12350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 6 st 12400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.2\n",
            "[log] ep 6 st 12450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 6 st 12500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 6 st 12550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 6 st 12600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 6 st 12650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 6 st 12700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 6 st 12750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.171s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 6 st 12800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.171s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 6 st 12850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 6 st 12900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 6 st 12950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.96 samp_s=30.7\n",
            "[log] ep 6 st 13000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.96 samp_s=30.8\n",
            "[save] step 13000 -> checkpoints/vla_step13000.pt\n",
            "[log] ep 6 st 13050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 6 st 13100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 6 st 13150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=29.9\n",
            "[log] ep 6 st 13200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 6 st 13250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 6 st 13300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 6 st 13350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 6 st 13400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 6 st 13450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 6 st 13500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 6 st 13550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 6 st 13600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 6 st 13650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 6 st 13700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 6 st 13750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.171s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 6 st 13800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 6 st 13850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.6\n",
            "[log] ep 6 st 13900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.172s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 6 st 13950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.96 samp_s=30.6\n",
            "[log] ep 6 st 14000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.96 samp_s=30.7\n",
            "[save] step 14000 -> checkpoints/vla_step14000.pt\n",
            "[epoch] 6 done in 2202.5s | avg_loss=nan\n",
            "[log] ep 7 st 14050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.185s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 7 st 14100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.177s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 7 st 14150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.175s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 7 st 14200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.174s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 7 st 14250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.174s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 7 st 14300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.173s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 7 st 14350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=29.9\n",
            "[log] ep 7 st 14400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 7 st 14450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 7 st 14500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 7 st 14550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 7 st 14600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 7 st 14650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.172s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 7 st 14700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.172s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 7 st 14750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.172s sp_s=0.95 samp_s=30.2\n",
            "[log] ep 7 st 14800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.172s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 7 st 14850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 7 st 14900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.207s bwd=0.171s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 7 st 14950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 7 st 15000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.4\n",
            "[save] step 15000 -> checkpoints/vla_step15000.pt\n",
            "[log] ep 7 st 15050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 7 st 15100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 7 st 15150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 7 st 15200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 7 st 15250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 7 st 15300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 7 st 15350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 7 st 15400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.1\n",
            "[log] ep 7 st 15450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 7 st 15500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.94 samp_s=30.2\n",
            "[log] ep 7 st 15550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 7 st 15600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 7 st 15650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.3\n",
            "[log] ep 7 st 15700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 7 st 15750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 7 st 15800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.4\n",
            "[log] ep 7 st 15850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 7 st 15900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 7 st 15950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.95 samp_s=30.5\n",
            "[log] ep 7 st 16000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.208s bwd=0.172s sp_s=0.96 samp_s=30.6\n",
            "[save] step 16000 -> checkpoints/vla_step16000.pt\n",
            "[epoch] 7 done in 2268.7s | avg_loss=nan\n",
            "[log] ep 8 st 16050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.178s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 8 st 16100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 8 st 16150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.92 samp_s=29.5\n",
            "[log] ep 8 st 16200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.92 samp_s=29.5\n",
            "[log] ep 8 st 16250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.92 samp_s=29.5\n",
            "[log] ep 8 st 16300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.92 samp_s=29.6\n",
            "[log] ep 8 st 16350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.175s sp_s=0.93 samp_s=29.6\n",
            "[log] ep 8 st 16400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.175s sp_s=0.93 samp_s=29.6\n",
            "[log] ep 8 st 16450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 8 st 16500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 8 st 16550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 8 st 16600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.174s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 8 st 16650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.174s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 8 st 16700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.174s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 8 st 16750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.174s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 8 st 16800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.174s sp_s=0.94 samp_s=29.9\n",
            "[log] ep 8 st 16850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.174s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 8 st 16900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 8 st 16950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 8 st 17000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.94 samp_s=30.1\n",
            "[save] step 17000 -> checkpoints/vla_step17000.pt\n",
            "[log] ep 8 st 17050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 8 st 17100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.174s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 8 st 17150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.92 samp_s=29.5\n",
            "[log] ep 8 st 17200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.92 samp_s=29.5\n",
            "[log] ep 8 st 17250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.92 samp_s=29.5\n",
            "[log] ep 8 st 17300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.92 samp_s=29.6\n",
            "[log] ep 8 st 17350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.6\n",
            "[log] ep 8 st 17400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.6\n",
            "[log] ep 8 st 17450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 8 st 17500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 8 st 17550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.7\n",
            "[log] ep 8 st 17600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 8 st 17650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 8 st 17700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.8\n",
            "[log] ep 8 st 17750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 8 st 17800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.93 samp_s=29.9\n",
            "[log] ep 8 st 17850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.94 samp_s=29.9\n",
            "[log] ep 8 st 17900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 8 st 17950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.94 samp_s=30.0\n",
            "[log] ep 8 st 18000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.209s bwd=0.173s sp_s=0.94 samp_s=30.0\n",
            "[save] step 18000 -> checkpoints/vla_step18000.pt\n",
            "[epoch] 8 done in 2433.9s | avg_loss=nan\n",
            "[log] ep 9 st 18050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.217s bwd=0.182s sp_s=0.90 samp_s=28.8\n",
            "[log] ep 9 st 18100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.213s bwd=0.176s sp_s=0.90 samp_s=28.9\n",
            "[log] ep 9 st 18150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.175s sp_s=0.90 samp_s=28.9\n",
            "[log] ep 9 st 18200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.90 samp_s=28.9\n",
            "[log] ep 9 st 18250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.91 samp_s=29.0\n",
            "[log] ep 9 st 18300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.173s sp_s=0.91 samp_s=29.0\n",
            "[log] ep 9 st 18350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.172s sp_s=0.91 samp_s=29.0\n",
            "[log] ep 9 st 18400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.173s sp_s=0.91 samp_s=29.1\n",
            "[log] ep 9 st 18450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.173s sp_s=0.91 samp_s=29.1\n",
            "[log] ep 9 st 18500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.173s sp_s=0.91 samp_s=29.1\n",
            "[log] ep 9 st 18550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.173s sp_s=0.91 samp_s=29.2\n",
            "[log] ep 9 st 18600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.173s sp_s=0.91 samp_s=29.2\n",
            "[log] ep 9 st 18650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.210s bwd=0.173s sp_s=0.91 samp_s=29.2\n",
            "[log] ep 9 st 18700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.173s sp_s=0.91 samp_s=29.2\n",
            "[log] ep 9 st 18750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.173s sp_s=0.91 samp_s=29.3\n",
            "[log] ep 9 st 18800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.173s sp_s=0.92 samp_s=29.3\n",
            "[log] ep 9 st 18850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.92 samp_s=29.3\n",
            "[log] ep 9 st 18900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 9 st 18950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.174s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 9 st 19000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.174s sp_s=0.92 samp_s=29.4\n",
            "[save] step 19000 -> checkpoints/vla_step19000.pt\n",
            "[log] ep 9 st 19050 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.174s sp_s=0.90 samp_s=28.9\n",
            "[log] ep 9 st 19100 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.174s sp_s=0.90 samp_s=28.9\n",
            "[log] ep 9 st 19150 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.174s sp_s=0.90 samp_s=29.0\n",
            "[log] ep 9 st 19200 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.174s sp_s=0.91 samp_s=29.0\n",
            "[log] ep 9 st 19250 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.174s sp_s=0.91 samp_s=29.0\n",
            "[log] ep 9 st 19300 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.212s bwd=0.175s sp_s=0.91 samp_s=29.1\n",
            "[log] ep 9 st 19350 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.91 samp_s=29.1\n",
            "[log] ep 9 st 19400 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.91 samp_s=29.1\n",
            "[log] ep 9 st 19450 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.174s sp_s=0.91 samp_s=29.1\n",
            "[log] ep 9 st 19500 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.91 samp_s=29.2\n",
            "[log] ep 9 st 19550 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.91 samp_s=29.2\n",
            "[log] ep 9 st 19600 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.91 samp_s=29.2\n",
            "[log] ep 9 st 19650 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.91 samp_s=29.3\n",
            "[log] ep 9 st 19700 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.92 samp_s=29.3\n",
            "[log] ep 9 st 19750 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.92 samp_s=29.3\n",
            "[log] ep 9 st 19800 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.92 samp_s=29.3\n",
            "[log] ep 9 st 19850 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 9 st 19900 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 9 st 19950 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.92 samp_s=29.4\n",
            "[log] ep 9 st 20000 loss=nan avg=nan lr=3.00e-04 mem=14.75/21.93GB load=0.024s fwd=0.211s bwd=0.175s sp_s=0.92 samp_s=29.5\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/vla_project/train.py\", line 14, in <module>\n",
            "    train_loop(cfg)\n",
            "  File \"/content/drive/MyDrive/vla_project/trainer.py\", line 196, in train_loop\n",
            "    save_checkpoint(path, target.state_dict())\n",
            "  File \"/content/drive/MyDrive/vla_project/util.py\", line 15, in save_checkpoint\n",
            "    torch.save(state_dict, path)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 828, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)  # type: ignore[arg-type]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 792, in __init__\n",
            "    torch._C.PyTorchFileWriter(\n",
            "RuntimeError: File checkpoints/vla_step20000.pt cannot be opened.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# deepseed\\n\\n%cd /content/vla_project\\n!deepspeed --num_gpus=1 train.py --deepspeed --deepspeed_config ds_config.json   --train_csv data/train.csv --val_csv data/val.csv --image_root .   --vision_backbone vit_base_patch14_dinov2   --text_model_name meta-llama/Meta-Llama-3-8B-Instruct   --img_size 224 --batch_size 2 --grad_accumulation_steps 2 --amp\\n\\n'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/vla_project\n",
        "\n",
        "!python train.py \\\n",
        "  --train_csv /content/drive/MyDrive/vla_datasets/export_vla/train.jsonl \\\n",
        "  --val_csv   /content/drive/MyDrive/vla_datasets/export_vla/val.jsonl \\\n",
        "  --image_root /content/drive/MyDrive/vla_datasets \\\n",
        "  --vision_backbone vit_base_patch14_dinov2 \\\n",
        "  --text_model_name meta-llama/Meta-Llama-3-8B-Instruct \\\n",
        "  --img_size 518 --batch_size 32 --amp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# deepseed\n",
        "\n",
        "%cd /content/vla_project\n",
        "!deepspeed --num_gpus=1 train.py --deepspeed --deepspeed_config ds_config.json \\\n",
        "  --train_csv data/train.csv --val_csv data/val.csv --image_root . \\\n",
        "  --vision_backbone vit_base_patch14_dinov2 \\\n",
        "  --text_model_name meta-llama/Meta-Llama-3-8B-Instruct \\\n",
        "  --img_size 224 --batch_size 2 --grad_accumulation_steps 2 --amp\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Tg7N8tZfje"
      },
      "source": [
        "시각화"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video, display\n",
        "display(Video(\"/content/drive/MyDrive/viz/run.mp4\", embed=True))"
      ],
      "metadata": {
        "id": "6XwmFgHTWUUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}