# VLA-
custome vision language action model pipeline(in progress)

### reference ###

1) VLA-ADAPTER: AN EFFECTIVE PARADIGM FOR TINY-SCALE VISION-LANGUAGE-ACTION MODEL
2) InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation


### citation ###

@article{yang2025instructvla,
          title={InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation},
          author={Yang, Shuai and Li, Hao and Chen, Yilun and Wang, Bin and Tian, Yang and Wang, Tai and Wang, Hanqing and Zhao, Feng and Liao, Yiyi and Pang, Jiangmiao},
          journal={arXiv preprint arXiv:2507.17520},
          year={2025}
        }

meta llama

dinov2
